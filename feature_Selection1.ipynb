{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d766c400-8227-47dc-8ec5-94a8e73076cf",
   "metadata": {},
   "source": [
    "# Loading dataset and taking few insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59009dd0-77f0-46cb-b81f-3759daf8280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "df = pd.read_csv(\"Final_Merged_INSAT_CPCB_ERA5_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f110f2f-a19f-44f8-becb-190611f06820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['state', 'station_id', 'station_location', 'latitude', 'longitude',\n",
       "       'timestamp_utc', 'PM2.5', 'img_mean', 'img_std', 'img_min', 'img_max',\n",
       "       'img_median', 'mean_TIR1', 'std_TIR1', 'min_TIR1', 'max_TIR1',\n",
       "       'median_TIR1', 'p25_TIR1', 'p75_TIR1', 'p90_TIR1', 'p95_TIR1',\n",
       "       'pct_above_240_TIR1', 'pct_below_50_TIR1', 'pct_above_200_TIR1',\n",
       "       'pct_below_100_TIR1', 'range_TIR1', 'cv_TIR1', 'skewness_TIR1',\n",
       "       'kurtosis_TIR1', 'mean_WV', 'std_WV', 'min_WV', 'max_WV', 'median_WV',\n",
       "       'p25_WV', 'p75_WV', 'p90_WV', 'p95_WV', 'pct_above_240_WV',\n",
       "       'pct_below_50_WV', 'pct_above_200_WV', 'pct_below_100_WV', 'range_WV',\n",
       "       'cv_WV', 'skewness_WV', 'kurtosis_WV', 'has_TIR1', 'has_WV', 't2m',\n",
       "       'd2m', 'u10', 'v10', 'blh', 'ssrd', 'tp', 'sp', 'skt', 'number',\n",
       "       'expver', 'grid_latitude', 'grid_longitude', 'wind_speed', 'wind_dir',\n",
       "       'rh', 't2m_lag1', 't2m_rolling3', 't2m_rolling24', 'd2m_lag1',\n",
       "       'd2m_rolling3', 'd2m_rolling24', 'wind_speed_lag1',\n",
       "       'wind_speed_rolling3', 'wind_speed_rolling24', 'tp_lag1', 'tp_rolling3',\n",
       "       'tp_rolling24', 'hour_utc', 'BCEXTTAU', 'DUEXTTAU', 'OCEXTTAU',\n",
       "       'SSEXTTAU', 'SUEXTTAU', 'TOTEXTTAU'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b15de2e9-9ab9-4087-977e-a98983710bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102720, 83)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c35b6291-5e3c-440f-941f-bf6868a66b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of               state station_id station_location  latitude  longitude  \\\n",
       "0             Delhi      DL009      Pusa, Delhi   28.6374    77.1577   \n",
       "1             Delhi      DL009      Pusa, Delhi   28.6374    77.1577   \n",
       "2             Delhi      DL009      Pusa, Delhi   28.6374    77.1577   \n",
       "3             Delhi      DL009      Pusa, Delhi   28.6374    77.1577   \n",
       "4             Delhi      DL009      Pusa, Delhi   28.6374    77.1577   \n",
       "...             ...        ...              ...       ...        ...   \n",
       "102715  Maharashtra      MH033   Deonar, Mumbai   19.0455    72.9188   \n",
       "102716  Maharashtra      MH033   Deonar, Mumbai   19.0455    72.9188   \n",
       "102717  Maharashtra      MH033   Deonar, Mumbai   19.0455    72.9188   \n",
       "102718  Maharashtra      MH033   Deonar, Mumbai   19.0455    72.9188   \n",
       "102719  Maharashtra      MH033   Deonar, Mumbai   19.0455    72.9188   \n",
       "\n",
       "                    timestamp_utc   PM2.5    img_mean   img_std     img_min  \\\n",
       "0       2021-01-01 02:00:00+00:00  311.95  303.507324  0.805942  300.558502   \n",
       "1       2021-01-01 03:00:00+00:00  441.33  303.507324  0.805942  300.558502   \n",
       "2       2021-01-01 04:00:00+00:00  628.92  303.507324  0.805942  300.558502   \n",
       "3       2021-01-01 05:00:00+00:00  505.02  303.507324  0.805942  300.558502   \n",
       "4       2021-01-01 06:00:00+00:00  468.68  303.507324  0.805942  300.558502   \n",
       "...                           ...     ...         ...       ...         ...   \n",
       "102715  2022-12-31 05:00:00+00:00  191.70  302.669525  3.045363  297.612091   \n",
       "102716  2022-12-31 06:00:00+00:00  184.29  302.669525  3.045363  297.612091   \n",
       "102717  2022-12-31 07:00:00+00:00  161.27  302.669525  3.045363  297.612091   \n",
       "102718  2022-12-31 08:00:00+00:00  134.69  302.669525  3.045363  297.612091   \n",
       "102719  2022-12-31 09:00:00+00:00  114.23  302.669525  3.045363  297.612091   \n",
       "\n",
       "        ...  tp_lag1  tp_rolling3  tp_rolling24  hour_utc  BCEXTTAU  DUEXTTAU  \\\n",
       "0       ...      0.0          0.0           0.0       2.0  0.045041  0.024928   \n",
       "1       ...      0.0          0.0           0.0       3.0  0.043295  0.025047   \n",
       "2       ...      0.0          0.0           0.0       4.0  0.042308  0.024866   \n",
       "3       ...      0.0          0.0           0.0       5.0  0.042029  0.024319   \n",
       "4       ...      0.0          0.0           0.0       6.0  0.088041  0.016295   \n",
       "...     ...      ...          ...           ...       ...       ...       ...   \n",
       "102715  ...      0.0          0.0           0.0       5.0  0.025731  0.015568   \n",
       "102716  ...      0.0          0.0           0.0       6.0  0.029159  0.014329   \n",
       "102717  ...      0.0          0.0           0.0       7.0  0.027911  0.013784   \n",
       "102718  ...      0.0          0.0           0.0       8.0  0.026707  0.013256   \n",
       "102719  ...      0.0          0.0           0.0       9.0  0.028401  0.012525   \n",
       "\n",
       "        OCEXTTAU  SSEXTTAU  SUEXTTAU  TOTEXTTAU  \n",
       "0       0.066587  0.001470  0.126601   0.264630  \n",
       "1       0.064742  0.001442  0.125056   0.259641  \n",
       "2       0.063684  0.001438  0.126321   0.258576  \n",
       "3       0.063856  0.001478  0.130974   0.262643  \n",
       "4       0.147634  0.003016  0.336788   0.591857  \n",
       "...          ...       ...       ...        ...  \n",
       "102715  0.045227  0.003525  0.103876   0.193932  \n",
       "102716  0.050505  0.004514  0.115866   0.214384  \n",
       "102717  0.047624  0.004260  0.110129   0.203721  \n",
       "102718  0.045001  0.004068  0.105854   0.194928  \n",
       "102719  0.047368  0.004269  0.112875   0.205450  \n",
       "\n",
       "[102720 rows x 83 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "711420ff-0c77-4e98-94c5-afa3132fd4f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of               state station_id station_location  latitude  longitude  \\\n",
       "0             Delhi      DL009      Pusa, Delhi   28.6374    77.1577   \n",
       "1             Delhi      DL009      Pusa, Delhi   28.6374    77.1577   \n",
       "2             Delhi      DL009      Pusa, Delhi   28.6374    77.1577   \n",
       "3             Delhi      DL009      Pusa, Delhi   28.6374    77.1577   \n",
       "4             Delhi      DL009      Pusa, Delhi   28.6374    77.1577   \n",
       "...             ...        ...              ...       ...        ...   \n",
       "102715  Maharashtra      MH033   Deonar, Mumbai   19.0455    72.9188   \n",
       "102716  Maharashtra      MH033   Deonar, Mumbai   19.0455    72.9188   \n",
       "102717  Maharashtra      MH033   Deonar, Mumbai   19.0455    72.9188   \n",
       "102718  Maharashtra      MH033   Deonar, Mumbai   19.0455    72.9188   \n",
       "102719  Maharashtra      MH033   Deonar, Mumbai   19.0455    72.9188   \n",
       "\n",
       "                    timestamp_utc   PM2.5    img_mean   img_std     img_min  \\\n",
       "0       2021-01-01 02:00:00+00:00  311.95  303.507324  0.805942  300.558502   \n",
       "1       2021-01-01 03:00:00+00:00  441.33  303.507324  0.805942  300.558502   \n",
       "2       2021-01-01 04:00:00+00:00  628.92  303.507324  0.805942  300.558502   \n",
       "3       2021-01-01 05:00:00+00:00  505.02  303.507324  0.805942  300.558502   \n",
       "4       2021-01-01 06:00:00+00:00  468.68  303.507324  0.805942  300.558502   \n",
       "...                           ...     ...         ...       ...         ...   \n",
       "102715  2022-12-31 05:00:00+00:00  191.70  302.669525  3.045363  297.612091   \n",
       "102716  2022-12-31 06:00:00+00:00  184.29  302.669525  3.045363  297.612091   \n",
       "102717  2022-12-31 07:00:00+00:00  161.27  302.669525  3.045363  297.612091   \n",
       "102718  2022-12-31 08:00:00+00:00  134.69  302.669525  3.045363  297.612091   \n",
       "102719  2022-12-31 09:00:00+00:00  114.23  302.669525  3.045363  297.612091   \n",
       "\n",
       "        ...  tp_lag1  tp_rolling3  tp_rolling24  hour_utc  BCEXTTAU  DUEXTTAU  \\\n",
       "0       ...      0.0          0.0           0.0       2.0  0.045041  0.024928   \n",
       "1       ...      0.0          0.0           0.0       3.0  0.043295  0.025047   \n",
       "2       ...      0.0          0.0           0.0       4.0  0.042308  0.024866   \n",
       "3       ...      0.0          0.0           0.0       5.0  0.042029  0.024319   \n",
       "4       ...      0.0          0.0           0.0       6.0  0.088041  0.016295   \n",
       "...     ...      ...          ...           ...       ...       ...       ...   \n",
       "102715  ...      0.0          0.0           0.0       5.0  0.025731  0.015568   \n",
       "102716  ...      0.0          0.0           0.0       6.0  0.029159  0.014329   \n",
       "102717  ...      0.0          0.0           0.0       7.0  0.027911  0.013784   \n",
       "102718  ...      0.0          0.0           0.0       8.0  0.026707  0.013256   \n",
       "102719  ...      0.0          0.0           0.0       9.0  0.028401  0.012525   \n",
       "\n",
       "        OCEXTTAU  SSEXTTAU  SUEXTTAU  TOTEXTTAU  \n",
       "0       0.066587  0.001470  0.126601   0.264630  \n",
       "1       0.064742  0.001442  0.125056   0.259641  \n",
       "2       0.063684  0.001438  0.126321   0.258576  \n",
       "3       0.063856  0.001478  0.130974   0.262643  \n",
       "4       0.147634  0.003016  0.336788   0.591857  \n",
       "...          ...       ...       ...        ...  \n",
       "102715  0.045227  0.003525  0.103876   0.193932  \n",
       "102716  0.050505  0.004514  0.115866   0.214384  \n",
       "102717  0.047624  0.004260  0.110129   0.203721  \n",
       "102718  0.045001  0.004068  0.105854   0.194928  \n",
       "102719  0.047368  0.004269  0.112875   0.205450  \n",
       "\n",
       "[102720 rows x 83 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164523e7-e3fc-4b67-a29d-c5818ea46088",
   "metadata": {},
   "source": [
    "## Measuring per Station Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79f43ffd-3306-41aa-a02c-0a27e88a6d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage summary (8 slots/day expected):\n",
      "       days_covered  expected_slots  actual_slots  coverage_pct\n",
      "count     20.000000       20.000000     20.000000     20.000000\n",
      "mean     723.500000     5788.000000   5136.000000      0.886905\n",
      "std       28.141559      225.132476    455.690569      0.065334\n",
      "min      604.000000     4832.000000   4039.000000      0.756164\n",
      "25%      730.000000     5840.000000   4870.750000      0.838124\n",
      "50%      730.000000     5840.000000   5182.500000      0.887414\n",
      "75%      730.000000     5840.000000   5487.250000      0.939598\n",
      "max      730.000000     5840.000000   5773.000000      0.988527\n",
      "\n",
      "Worst 10 stations by coverage:\n",
      "  station_id                     start                       end  \\\n",
      "0      HR002 2021-01-01 02:00:00+00:00 2022-12-31 09:00:00+00:00   \n",
      "1      MH012 2021-01-01 02:00:00+00:00 2022-12-31 09:00:00+00:00   \n",
      "2      HR001 2021-01-01 05:00:00+00:00 2022-12-31 09:00:00+00:00   \n",
      "3      MH007 2021-01-01 04:00:00+00:00 2022-12-31 04:00:00+00:00   \n",
      "4      KA002 2021-01-01 02:00:00+00:00 2022-08-27 09:00:00+00:00   \n",
      "5      DL009 2021-01-01 02:00:00+00:00 2022-12-31 09:00:00+00:00   \n",
      "6      KA007 2021-01-01 02:00:00+00:00 2022-12-31 09:00:00+00:00   \n",
      "7      MH026 2021-01-01 02:00:00+00:00 2022-12-31 09:00:00+00:00   \n",
      "8      KA001 2021-01-05 05:00:00+00:00 2022-12-31 09:00:00+00:00   \n",
      "9      MH033 2021-01-01 02:00:00+00:00 2022-12-31 09:00:00+00:00   \n",
      "\n",
      "   days_covered  expected_slots  actual_slots  coverage_pct  \n",
      "0           730            5840          4416      0.756164  \n",
      "1           730            5840          4698      0.804452  \n",
      "2           730            5840          4748      0.813014  \n",
      "3           730            5840          4786      0.819521  \n",
      "4           604            4832          4039      0.835886  \n",
      "5           730            5840          4899      0.838870  \n",
      "6           730            5840          4955      0.848459  \n",
      "7           730            5840          4959      0.849144  \n",
      "8           726            5808          5071      0.873106  \n",
      "9           730            5840          5155      0.882705  \n",
      "\n",
      "Best 10 stations by coverage:\n",
      "   station_id                     start                       end  \\\n",
      "10      HR009 2021-01-01 02:00:00+00:00 2022-12-31 09:00:00+00:00   \n",
      "11      MH004 2021-01-01 03:00:00+00:00 2022-12-31 09:00:00+00:00   \n",
      "12      DL011 2021-01-01 02:00:00+00:00 2022-12-31 09:00:00+00:00   \n",
      "13      KA015 2021-01-01 02:00:00+00:00 2022-12-31 09:00:00+00:00   \n",
      "14      HR004 2021-01-01 02:00:00+00:00 2022-12-31 09:00:00+00:00   \n",
      "15      KA018 2021-01-01 04:00:00+00:00 2022-12-31 09:00:00+00:00   \n",
      "16      HR003 2021-01-01 02:00:00+00:00 2022-12-31 08:00:00+00:00   \n",
      "17      DL022 2021-01-01 02:00:00+00:00 2022-12-31 09:00:00+00:00   \n",
      "18      DL029 2021-01-01 02:00:00+00:00 2022-12-31 09:00:00+00:00   \n",
      "19      DL024 2021-01-01 02:00:00+00:00 2022-12-31 09:00:00+00:00   \n",
      "\n",
      "    days_covered  expected_slots  actual_slots  coverage_pct  \n",
      "10           730            5840          5210      0.892123  \n",
      "11           730            5840          5311      0.909418  \n",
      "12           730            5840          5360      0.917808  \n",
      "13           730            5840          5391      0.923116  \n",
      "14           730            5840          5472      0.936986  \n",
      "15           730            5840          5533      0.947432  \n",
      "16           730            5840          5552      0.950685  \n",
      "17           730            5840          5641      0.965925  \n",
      "18           730            5840          5751      0.984760  \n",
      "19           730            5840          5773      0.988527  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "fn = \"Final_Merged_INSAT_CPCB_ERA5_filtered.csv\"\n",
    "df = pd.read_csv(fn, parse_dates=[\"timestamp_utc\"])\n",
    "df[\"timestamp_utc\"] = pd.to_datetime(df[\"timestamp_utc\"], utc=True)\n",
    "\n",
    "# Sort for safety\n",
    "df = df.sort_values([\"station_id\", \"timestamp_utc\"]).reset_index(drop=True)\n",
    "\n",
    "# Function to compute coverage based on 8-hour schedule\n",
    "def station_coverage(df, station_col=\"station_id\", time_col=\"timestamp_utc\", slots_per_day=8):\n",
    "    rows = []\n",
    "    for station, g in df.groupby(station_col):\n",
    "        start = g[time_col].min()\n",
    "        end = g[time_col].max()\n",
    "        # number of days between first and last record\n",
    "        total_days = (end.normalize() - start.normalize()).days + 1\n",
    "        expected = total_days * slots_per_day\n",
    "        actual = g[time_col].nunique()\n",
    "        pct = actual / expected if expected > 0 else 0\n",
    "        rows.append((station, start, end, total_days, expected, actual, pct))\n",
    "    return pd.DataFrame(rows, columns=[\n",
    "        station_col, \"start\", \"end\", \"days_covered\", \"expected_slots\", \"actual_slots\", \"coverage_pct\"\n",
    "    ])\n",
    "\n",
    "# Run coverage calc\n",
    "cov = station_coverage(df)\n",
    "\n",
    "# Sort by coverage %\n",
    "cov = cov.sort_values(\"coverage_pct\").reset_index(drop=True)\n",
    "\n",
    "# Show summary\n",
    "print(\"Coverage summary (8 slots/day expected):\")\n",
    "print(cov.describe())\n",
    "\n",
    "print(\"\\nWorst 10 stations by coverage:\")\n",
    "print(cov.head(10))\n",
    "\n",
    "print(\"\\nBest 10 stations by coverage:\")\n",
    "print(cov.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "955f6ba1-d393-4e50-8d32-4a047fee1f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  station_id             timestamp_utc  low_coverage_flag\n",
      "0      DL009 2021-01-01 02:00:00+00:00               True\n",
      "1      DL009 2021-01-01 03:00:00+00:00               True\n",
      "2      DL009 2021-01-01 04:00:00+00:00               True\n",
      "3      DL009 2021-01-01 05:00:00+00:00               True\n",
      "4      DL009 2021-01-01 06:00:00+00:00               True\n"
     ]
    }
   ],
   "source": [
    "## Adding flag for the lower coverage stations. \n",
    "# Expected coverage calculation (2 years, hourly data → ~17,520 hours)\n",
    "expected_hours = ((df[\"timestamp_utc\"].max() - df[\"timestamp_utc\"].min()).days + 1) * 24\n",
    "\n",
    "# Calculate coverage for each station\n",
    "coverage = (\n",
    "    df.groupby(\"station_id\")[\"timestamp_utc\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"available_hours\")\n",
    ")\n",
    "\n",
    "coverage[\"coverage_ratio\"] = coverage[\"available_hours\"] / expected_hours\n",
    "\n",
    "# Define threshold for low coverage (80%)\n",
    "threshold = 0.8\n",
    "coverage[\"low_coverage_flag\"] = coverage[\"coverage_ratio\"] < threshold\n",
    "\n",
    "# Merge back to original dataframe\n",
    "df = df.merge(\n",
    "    coverage[[\"station_id\", \"low_coverage_flag\"]],\n",
    "    on=\"station_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(df[[\"station_id\", \"timestamp_utc\", \"low_coverage_flag\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c754556d-47d6-45fb-a962-ed7d306b6861",
   "metadata": {},
   "source": [
    "# Adding timestamp_ist column to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "149953cc-0243-447a-9683-09ebc6e372fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              timestamp_utc             timestamp_ist\n",
      "0 2021-01-01 02:00:00+00:00 2021-01-01 07:30:00+05:30\n",
      "1 2021-01-01 03:00:00+00:00 2021-01-01 08:30:00+05:30\n",
      "2 2021-01-01 04:00:00+00:00 2021-01-01 09:30:00+05:30\n",
      "3 2021-01-01 05:00:00+00:00 2021-01-01 10:30:00+05:30\n",
      "4 2021-01-01 06:00:00+00:00 2021-01-01 11:30:00+05:30\n"
     ]
    }
   ],
   "source": [
    "# assume df already loaded with timestamp_utc in UTC timezone\n",
    "# make sure it's parsed correctly as timezone-aware datetime\n",
    "df[\"timestamp_utc\"] = pd.to_datetime(df[\"timestamp_utc\"], utc=True)\n",
    "\n",
    "# convert to IST\n",
    "df[\"timestamp_ist\"] = df[\"timestamp_utc\"].dt.tz_convert(\"Asia/Kolkata\")\n",
    "\n",
    "# sanity check\n",
    "print(df[[\"timestamp_utc\", \"timestamp_ist\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10db9060-2e9c-43be-b0e1-627e89e67b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b78f0d7-feff-44ff-b6e6-3bd7bc7a075e",
   "metadata": {},
   "source": [
    "## Code for Gap Classification & Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cd6557-2d28-403a-af6b-d2f9edcf7060",
   "metadata": {},
   "source": [
    "### Compute gap lengths per row (per station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85be21f6-16e5-45ab-a195-8f0213ee094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumes df has columns: station_id, timestamp_utc (already sorted earlier)\n",
    "df = df.sort_values([\"station_id\", \"timestamp_utc\"]).reset_index(drop=True)\n",
    "\n",
    "# compute time difference from previous and next timestamp within each station\n",
    "df[\"prev_ts\"] = df.groupby(\"station_id\")[\"timestamp_utc\"].shift(1)\n",
    "df[\"next_ts\"] = df.groupby(\"station_id\")[\"timestamp_utc\"].shift(-1)\n",
    "\n",
    "df[\"gap_from_prev_h\"] = (df[\"timestamp_utc\"] - df[\"prev_ts\"]) / pd.Timedelta(hours=1)\n",
    "df[\"gap_to_next_h\"] = (df[\"next_ts\"] - df[\"timestamp_utc\"]) / pd.Timedelta(hours=1)\n",
    "\n",
    "def classify_gap(row):\n",
    "    # Look at both previous and next gaps\n",
    "    g_prev, g_next = row[\"gap_from_prev_h\"], row[\"gap_to_next_h\"]\n",
    "    g = min(g_prev if not pd.isna(g_prev) else np.inf,\n",
    "            g_next if not pd.isna(g_next) else np.inf)\n",
    "    if g <= 3:\n",
    "        return \"short\"\n",
    "    elif g <= 24:\n",
    "        return \"medium\"\n",
    "    elif g < np.inf:\n",
    "        return \"long\"\n",
    "    else:\n",
    "        return \"none\"  # start/end rows\n",
    "df[\"gap_class\"] = df.apply(classify_gap, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becb3917-af94-46ae-9b12-cc3c8924c9c5",
   "metadata": {},
   "source": [
    "#### Imputation logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7577a021-8ee6-4462-bd65-3850b1a316cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric columns for imputation\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "# drop columns that should not be imputed\n",
    "exclude = [\"latitude\", \"longitude\"] if \"latitude\" in df.columns else []\n",
    "num_cols = [c for c in num_cols if c not in exclude]\n",
    "\n",
    "# add imputed flag column\n",
    "df[\"is_imputed\"] = False\n",
    "\n",
    "def impute_station(g):\n",
    "    g = g.sort_values(\"timestamp_utc\").copy()\n",
    "    \n",
    "    # short gaps → ffill + bfill\n",
    "    g[num_cols] = g[num_cols].fillna(method=\"ffill\", limit=3).fillna(method=\"bfill\", limit=3)\n",
    "    \n",
    "    # medium gaps → linear interpolation\n",
    "    g[num_cols] = g[num_cols].interpolate(method=\"linear\", limit=24, limit_direction=\"both\")\n",
    "    \n",
    "    # mark imputed values\n",
    "    for col in num_cols:\n",
    "        g[\"is_imputed\"] |= g[col].isna()\n",
    "    \n",
    "    return g\n",
    "\n",
    "df = df.groupby(\"station_id\").apply(impute_station).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e96b8b-ea04-427b-b262-b66dff8423bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c17b6157-b4d0-495d-bfaa-9b224fe290b6",
   "metadata": {},
   "source": [
    "## Feature selections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878ed778-08f5-4dd2-afd2-bb5b38555d76",
   "metadata": {},
   "source": [
    "### Derived Meteorological Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c80cc2d-75a8-4511-8f37-1b8d1d2784fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wind vector components\n",
    "df[\"wind_dir_rad\"] = np.deg2rad(df[\"wind_dir\"].fillna(0))\n",
    "df[\"wind_u\"] = df[\"wind_speed\"] * np.cos(df[\"wind_dir_rad\"])\n",
    "df[\"wind_v\"] = df[\"wind_speed\"] * np.sin(df[\"wind_dir_rad\"])\n",
    "\n",
    "# Atmospheric stability\n",
    "df[\"stability\"] = (df[\"t2m\"] - df[\"skt\"].fillna(df[\"t2m\"])) / df[\"blh\"].replace(0, np.nan)\n",
    "\n",
    "# Moisture deficit\n",
    "df[\"moisture_deficit\"] = df[\"t2m\"] - df[\"d2m\"]\n",
    "\n",
    "# Thermal inversion strength\n",
    "df[\"inversion_strength\"] = df[\"mean_TIR1\"] - df[\"t2m\"]\n",
    "\n",
    "# Pressure tendency (difference vs previous hour)\n",
    "df[\"dp_dt\"] = df.groupby(\"station_id\")[\"sp\"].diff(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75d32f7-26fd-453b-8c27-273395e8ab2f",
   "metadata": {},
   "source": [
    "### Timestamp Cyclic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94102715-edd1-4600-84c1-0e46c0849244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hour, day of year, and cyclical encodings\n",
    "df[\"hour\"] = df[\"timestamp_utc\"].dt.hour\n",
    "df[\"hour_sin\"] = np.sin(2 * np.pi * df[\"hour\"] / 24)\n",
    "df[\"hour_cos\"] = np.cos(2 * np.pi * df[\"hour\"] / 24)\n",
    "\n",
    "df[\"dayofyear\"] = df[\"timestamp_utc\"].dt.dayofyear\n",
    "df[\"doy_sin\"] = np.sin(2 * np.pi * df[\"dayofyear\"] / 365)\n",
    "df[\"doy_cos\"] = np.cos(2 * np.pi * df[\"dayofyear\"] / 365)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1e999d-01f8-48fe-8285-abd1b2bd16bb",
   "metadata": {},
   "source": [
    "### Lags & Rolling Features (per-station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "924f87b6-8e13-415f-9860-416e3bbe2ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = [1, 3, 24]\n",
    "rolls = [3, 24]\n",
    "base_feats = [\"PM2.5\", \"t2m\", \"rh\", \"wind_speed\", \"mean_TIR1\", \"TOTEXTTAU\"]\n",
    "\n",
    "for lag in lags:\n",
    "    for f in base_feats:\n",
    "        df[f\"{f}_lag{lag}\"] = df.groupby(\"station_id\")[f].shift(lag)\n",
    "\n",
    "for r in rolls:\n",
    "    for f in base_feats:\n",
    "        df[f\"{f}_rolling{r}_mean\"] = (\n",
    "            df.groupby(\"station_id\")[f]\n",
    "              .rolling(window=r, min_periods=1)\n",
    "              .mean()\n",
    "              .reset_index(level=0, drop=True)\n",
    "        )\n",
    "        df[f\"{f}_rolling{r}_std\"] = (\n",
    "            df.groupby(\"station_id\")[f]\n",
    "              .rolling(window=r, min_periods=1)\n",
    "              .std()\n",
    "              .reset_index(level=0, drop=True)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993615ab-f2fe-419c-afb6-1fdcb2fd2f26",
   "metadata": {},
   "source": [
    "# Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86715fa7-c3fe-4d9c-b035-6f0d4159cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"dataset_feature1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8af503-7537-4963-b555-a7060f9f6896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
