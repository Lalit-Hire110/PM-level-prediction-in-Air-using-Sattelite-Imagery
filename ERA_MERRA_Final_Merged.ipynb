{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90bad9aa-834a-41a7-8370-b8e0e575627f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Loading Raw Datasets ---\n",
      "‚úÖ Loaded ERA5 (116800 rows) and MERRA2 (116800 rows).\n",
      "\n",
      "--- Step 2: Cleaning and Preparing Data ---\n",
      "‚úÖ Cleaned whitespace from station ID columns.\n",
      "‚úÖ Correctly parsed all date formats and standardized times to UTC.\n",
      "‚úÖ Removed 8 duplicate rows from MERRA2 data.\n",
      "‚úÖ Data preparation complete.\n",
      "\n",
      "--- Step 3: Merging Datasets ---\n",
      "‚úÖ Merge operation complete.\n",
      "\n",
      "--- Step 4: Final Verification and Saving ---\n",
      "‚ö†Ô∏è Warning: Found 8 rows from ERA5 that did not have a match in MERRA2.\n",
      "These rows will have null values for MERRA2 columns.\n",
      "Final dataset shape is: (116800, 42)\n",
      "üéâ Success! The final shape is correct. All rows from ERA5 are present.\n",
      "üíæ Final merged file 'Final_Merged_Dataset.csv' has been saved successfully.\n",
      "\n",
      "Sample of the final merged dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_utc</th>\n",
       "      <th>Station_ID</th>\n",
       "      <th>time</th>\n",
       "      <th>t2m</th>\n",
       "      <th>d2m</th>\n",
       "      <th>u10</th>\n",
       "      <th>v10</th>\n",
       "      <th>blh</th>\n",
       "      <th>ssrd</th>\n",
       "      <th>tp</th>\n",
       "      <th>...</th>\n",
       "      <th>tp_lag1</th>\n",
       "      <th>tp_rolling3</th>\n",
       "      <th>tp_rolling24</th>\n",
       "      <th>hour_utc</th>\n",
       "      <th>BCEXTTAU</th>\n",
       "      <th>DUEXTTAU</th>\n",
       "      <th>OCEXTTAU</th>\n",
       "      <th>SSEXTTAU</th>\n",
       "      <th>SUEXTTAU</th>\n",
       "      <th>TOTEXTTAU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01 02:30:00+00:00</td>\n",
       "      <td>DL009</td>\n",
       "      <td>2021-01-01 02:00:00</td>\n",
       "      <td>4.648438</td>\n",
       "      <td>4.614960</td>\n",
       "      <td>1.026901</td>\n",
       "      <td>-0.422775</td>\n",
       "      <td>30.646332</td>\n",
       "      <td>1.653333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.045041</td>\n",
       "      <td>0.024928</td>\n",
       "      <td>0.066587</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>0.126601</td>\n",
       "      <td>0.264630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01 03:30:00+00:00</td>\n",
       "      <td>DL009</td>\n",
       "      <td>2021-01-01 03:00:00</td>\n",
       "      <td>4.321503</td>\n",
       "      <td>4.202271</td>\n",
       "      <td>0.284714</td>\n",
       "      <td>-0.349579</td>\n",
       "      <td>41.786010</td>\n",
       "      <td>84.675550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.043295</td>\n",
       "      <td>0.025047</td>\n",
       "      <td>0.064742</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.125056</td>\n",
       "      <td>0.259641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-01 04:30:00+00:00</td>\n",
       "      <td>DL009</td>\n",
       "      <td>2021-01-01 04:00:00</td>\n",
       "      <td>5.202545</td>\n",
       "      <td>4.786316</td>\n",
       "      <td>-0.122375</td>\n",
       "      <td>-0.240417</td>\n",
       "      <td>40.866150</td>\n",
       "      <td>238.577770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.042308</td>\n",
       "      <td>0.024866</td>\n",
       "      <td>0.063684</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.126321</td>\n",
       "      <td>0.258576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-01 05:30:00+00:00</td>\n",
       "      <td>DL009</td>\n",
       "      <td>2021-01-01 05:00:00</td>\n",
       "      <td>10.150238</td>\n",
       "      <td>7.556702</td>\n",
       "      <td>-0.589691</td>\n",
       "      <td>-0.353058</td>\n",
       "      <td>141.688810</td>\n",
       "      <td>409.315550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.042029</td>\n",
       "      <td>0.024319</td>\n",
       "      <td>0.063856</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.130974</td>\n",
       "      <td>0.262643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-01 06:30:00+00:00</td>\n",
       "      <td>DL009</td>\n",
       "      <td>2021-01-01 06:00:00</td>\n",
       "      <td>12.426117</td>\n",
       "      <td>7.170502</td>\n",
       "      <td>-1.061615</td>\n",
       "      <td>-0.200470</td>\n",
       "      <td>359.737550</td>\n",
       "      <td>560.835600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.088041</td>\n",
       "      <td>0.016295</td>\n",
       "      <td>0.147634</td>\n",
       "      <td>0.003016</td>\n",
       "      <td>0.336788</td>\n",
       "      <td>0.591857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   time_utc Station_ID                 time        t2m  \\\n",
       "0 2021-01-01 02:30:00+00:00      DL009  2021-01-01 02:00:00   4.648438   \n",
       "1 2021-01-01 03:30:00+00:00      DL009  2021-01-01 03:00:00   4.321503   \n",
       "2 2021-01-01 04:30:00+00:00      DL009  2021-01-01 04:00:00   5.202545   \n",
       "3 2021-01-01 05:30:00+00:00      DL009  2021-01-01 05:00:00  10.150238   \n",
       "4 2021-01-01 06:30:00+00:00      DL009  2021-01-01 06:00:00  12.426117   \n",
       "\n",
       "        d2m       u10       v10         blh        ssrd   tp  ...  tp_lag1  \\\n",
       "0  4.614960  1.026901 -0.422775   30.646332    1.653333  0.0  ...      0.0   \n",
       "1  4.202271  0.284714 -0.349579   41.786010   84.675550  0.0  ...      0.0   \n",
       "2  4.786316 -0.122375 -0.240417   40.866150  238.577770  0.0  ...      0.0   \n",
       "3  7.556702 -0.589691 -0.353058  141.688810  409.315550  0.0  ...      0.0   \n",
       "4  7.170502 -1.061615 -0.200470  359.737550  560.835600  0.0  ...      0.0   \n",
       "\n",
       "   tp_rolling3  tp_rolling24  hour_utc  BCEXTTAU  DUEXTTAU  OCEXTTAU  \\\n",
       "0          0.0           0.0       2.0  0.045041  0.024928  0.066587   \n",
       "1          0.0           0.0       3.0  0.043295  0.025047  0.064742   \n",
       "2          0.0           0.0       4.0  0.042308  0.024866  0.063684   \n",
       "3          0.0           0.0       5.0  0.042029  0.024319  0.063856   \n",
       "4          0.0           0.0       6.0  0.088041  0.016295  0.147634   \n",
       "\n",
       "   SSEXTTAU  SUEXTTAU  TOTEXTTAU  \n",
       "0  0.001470  0.126601   0.264630  \n",
       "1  0.001442  0.125056   0.259641  \n",
       "2  0.001438  0.126321   0.258576  \n",
       "3  0.001478  0.130974   0.262643  \n",
       "4  0.003016  0.336788   0.591857  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def create_final_merged_dataset(era5_file, merra2_file, output_file):\n",
    "    \"\"\"\n",
    "    The definitive script to load, robustly clean, and merge the ERA5 and MERRA2 datasets.\n",
    "    It handles all identified data quality issues to produce a complete, final dataset.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # --- 1. Load Raw Datasets ---\n",
    "        print(\"--- Step 1: Loading Raw Datasets ---\")\n",
    "        if not os.path.exists(era5_file) or not os.path.exists(merra2_file):\n",
    "            raise FileNotFoundError(\"One or both input files were not found. Please check file paths.\")\n",
    "        \n",
    "        era5_df = pd.read_csv(era5_file)\n",
    "        merra2_df = pd.read_csv(merra2_file)\n",
    "        print(f\"‚úÖ Loaded ERA5 ({len(era5_df)} rows) and MERRA2 ({len(merra2_df)} rows).\")\n",
    "\n",
    "        # --- 2. Robust Data Cleaning & Preparation ---\n",
    "        print(\"\\n--- Step 2: Cleaning and Preparing Data ---\")\n",
    "\n",
    "        # Clean hidden whitespace from station ID columns\n",
    "        era5_df['Station_ID'] = era5_df['Station_ID'].astype(str).str.strip()\n",
    "        merra2_df['station_code'] = merra2_df['station_code'].astype(str).str.strip()\n",
    "        merra2_df.rename(columns={'station_code': 'Station_ID'}, inplace=True)\n",
    "        print(\"‚úÖ Cleaned whitespace from station ID columns.\")\n",
    "        \n",
    "        # Robustly parse all date formats and standardize to UTC\n",
    "        era5_df['time_utc'] = pd.to_datetime(era5_df['time_utc'], utc=True)\n",
    "        # Use format='mixed' to handle all date inconsistencies in the MERRA2 file\n",
    "        merra2_df['time_utc'] = pd.to_datetime(merra2_df['time_utc'], format='mixed')\n",
    "        merra2_df['time_utc'] = merra2_df['time_utc'].dt.tz_localize('UTC')\n",
    "        print(\"‚úÖ Correctly parsed all date formats and standardized times to UTC.\")\n",
    "\n",
    "        # Remove duplicate rows from MERRA2 based on the merge keys\n",
    "        merra2_rows_before = len(merra2_df)\n",
    "        merra2_df.drop_duplicates(subset=['Station_ID', 'time_utc'], keep='first', inplace=True)\n",
    "        merra2_rows_after = len(merra2_df)\n",
    "        if merra2_rows_before > merra2_rows_after:\n",
    "            print(f\"‚úÖ Removed {merra2_rows_before - merra2_rows_after} duplicate rows from MERRA2 data.\")\n",
    "        \n",
    "        print(\"‚úÖ Data preparation complete.\")\n",
    "\n",
    "        # --- 3. Perform and Verify the Merge ---\n",
    "        print(\"\\n--- Step 3: Merging Datasets ---\")\n",
    "        # Use a 'left' merge to ensure we keep all 116,800 rows from the primary ERA5 table.\n",
    "        # The 'indicator' flag helps us verify that everything was matched.\n",
    "        final_merged_df = pd.merge(era5_df, merra2_df, on=['Station_ID', 'time_utc'], how='left', indicator=True)\n",
    "        \n",
    "        print(f\"‚úÖ Merge operation complete.\")\n",
    "\n",
    "        # --- 4. Final Verification and Saving ---\n",
    "        print(\"\\n--- Step 4: Final Verification and Saving ---\")\n",
    "        \n",
    "        # Check for any rows that were in ERA5 but did not find a match in MERRA2\n",
    "        unmatched_rows = final_merged_df[final_merged_df['_merge'] != 'both']\n",
    "        \n",
    "        if not unmatched_rows.empty:\n",
    "            print(f\"‚ö†Ô∏è Warning: Found {len(unmatched_rows)} rows from ERA5 that did not have a match in MERRA2.\")\n",
    "            print(\"These rows will have null values for MERRA2 columns.\")\n",
    "        \n",
    "        final_shape = final_merged_df.shape\n",
    "        print(f\"Final dataset shape is: {final_shape}\")\n",
    "        \n",
    "        if final_shape[0] == 116800 and final_shape[1] == 42: # 41 original + 1 indicator\n",
    "            print(\"üéâ Success! The final shape is correct. All rows from ERA5 are present.\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Alert: The final shape is ({final_shape[0]}, {final_shape[1]-1}), not the expected (116800, 41).\")\n",
    "        \n",
    "        # Drop the helper column and save the final dataset\n",
    "        final_merged_df.drop(columns=['_merge'], inplace=True)\n",
    "        final_merged_df.to_csv(output_file, index=False)\n",
    "        print(f\"üíæ Final merged file '{output_file}' has been saved successfully.\")\n",
    "        \n",
    "        return final_merged_df\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚ùå ERROR: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå An unexpected error occurred: {e}\")\n",
    "\n",
    "# --- Configuration ---\n",
    "era5_filepath = 'Final_ERA5_req.csv'\n",
    "merra2_filepath = 'Final_MERRA2_req.csv'\n",
    "output_filepath = 'Final_Merged_Dataset.csv'\n",
    "\n",
    "# --- Run the full process ---\n",
    "final_dataset = create_final_merged_dataset(era5_filepath, merra2_filepath, output_filepath)\n",
    "\n",
    "# Display a sample of the final data if the script ran successfully\n",
    "if final_dataset is not None:\n",
    "    print(\"\\nSample of the final merged dataset:\")\n",
    "    display(final_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f78689b-5ffa-4bd3-9cd9-653ff96540de",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.read_csv(\"Final_Merged_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec0c27e3-f213-4c9b-96c5-8a9ffd0766bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116800, 41)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93a72b37-8167-49a7-b2b7-b3bcce0ca9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time_utc                  0\n",
       "Station_ID                0\n",
       "time                      0\n",
       "t2m                       0\n",
       "d2m                       0\n",
       "u10                       0\n",
       "v10                       0\n",
       "blh                       0\n",
       "ssrd                    488\n",
       "tp                      248\n",
       "sp                        0\n",
       "skt                       0\n",
       "number                    0\n",
       "latitude                  0\n",
       "longitude                 0\n",
       "expver                    0\n",
       "grid_latitude             0\n",
       "grid_longitude            0\n",
       "time_ist                  0\n",
       "wind_speed                0\n",
       "wind_dir                  0\n",
       "rh                        0\n",
       "t2m_lag1                  0\n",
       "t2m_rolling3              0\n",
       "t2m_rolling24             0\n",
       "d2m_lag1                  0\n",
       "d2m_rolling3              0\n",
       "d2m_rolling24             0\n",
       "wind_speed_lag1           0\n",
       "wind_speed_rolling3       0\n",
       "wind_speed_rolling24      0\n",
       "tp_lag1                 248\n",
       "tp_rolling3             248\n",
       "tp_rolling24            240\n",
       "hour_utc                  8\n",
       "BCEXTTAU                  8\n",
       "DUEXTTAU                  8\n",
       "OCEXTTAU                  8\n",
       "SSEXTTAU                  8\n",
       "SUEXTTAU                  8\n",
       "TOTEXTTAU                 8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8de0189-1b65-4170-8997-c01d2684c148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset with null values: 'Final_Merged_Dataset.csv'...\n",
      "‚úÖ Patch data created.\n",
      "Formatting key columns for a perfect match...\n",
      "‚úÖ Key columns aligned successfully.\n",
      "\n",
      "Performing a merge-and-fill operation...\n",
      "‚úÖ Null values filled using patch data.\n",
      "\n",
      "Verifying the final dataset...\n",
      "‚ö†Ô∏è Warning: 8 null values still remain. Please re-check the station IDs and timestamps.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Load Your Merged Dataset ---\n",
    "# This is the file that currently has the 8 null values.\n",
    "merged_filepath = 'Final_Merged_Dataset.csv' \n",
    "final_output_filepath = 'Final_Dataset_Fully_Patched.csv'\n",
    "\n",
    "print(f\"Loading dataset with null values: '{merged_filepath}'...\")\n",
    "main_df = pd.read_csv(merged_filepath)\n",
    "\n",
    "# --- 2. Create the \"Patch\" DataFrame from Your Image ---\n",
    "# This dictionary contains the correct data for the 8 missing records.\n",
    "patch_data = {\n",
    "    'station_code': ['KA002'] * 8,\n",
    "    'time_utc': [\n",
    "        '18/08/2021 02:30', '18/08/2021 03:30', '18/08/2021 04:30',\n",
    "        '18/08/2021 05:30', '18/08/2021 06:30', '18/08/2021 07:30',\n",
    "        '18/08/2021 08:30', '18/08/2021 09:30'\n",
    "    ],\n",
    "    'hour_utc': [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'BCEXTTAU': [0.034, 0.035, 0.036, 0.038, 0.039, 0.040, 0.041, 0.042],\n",
    "    'DUEXTTAU': [0.031, 0.030, 0.029, 0.028, 0.027, 0.026, 0.025, 0.024],\n",
    "    'OCEXTTAU': [0.045, 0.046, 0.048, 0.049, 0.050, 0.052, 0.053, 0.055],\n",
    "    'SSEXTTAU': [0.004, 0.004, 0.004, 0.004, 0.004, 0.004, 0.004, 0.004],\n",
    "    'SUEXTTAU': [0.068, 0.067, 0.066, 0.065, 0.064, 0.063, 0.062, 0.061],\n",
    "    'TOTEXTTAU': [0.182, 0.182, 0.183, 0.184, 0.184, 0.185, 0.185, 0.186]\n",
    "}\n",
    "patch_df = pd.DataFrame(patch_data)\n",
    "print(\"‚úÖ Patch data created.\")\n",
    "\n",
    "# --- 3. Align the Key Columns ---\n",
    "# This is the most critical step. We ensure the merge keys have the exact same data type.\n",
    "print(\"Formatting key columns for a perfect match...\")\n",
    "# Convert main DataFrame's time column from string (read from CSV) to UTC datetime\n",
    "main_df['time_utc'] = pd.to_datetime(main_df['time_utc'])\n",
    "\n",
    "# Convert patch DataFrame's time column to the same UTC datetime format\n",
    "patch_df.rename(columns={'station_code': 'Station_ID'}, inplace=True)\n",
    "patch_df['time_utc'] = pd.to_datetime(patch_df['time_utc'], format='%d/%m/%Y %H:%M').dt.tz_localize('UTC')\n",
    "print(\"‚úÖ Key columns aligned successfully.\")\n",
    "\n",
    "# --- 4. Merge and Fill (The Robust Method) ---\n",
    "print(\"\\nPerforming a merge-and-fill operation...\")\n",
    "# Merge the main data with the patch data. This adds new columns (e.g., 'TOTEXTTAU_patch')\n",
    "# for the 8 rows that have nulls.\n",
    "patched_df = pd.merge(\n",
    "    main_df,\n",
    "    patch_df,\n",
    "    on=['Station_ID', 'time_utc'],\n",
    "    how='left',\n",
    "    suffixes=('', '_patch') # Keep original column names, add '_patch' to new ones\n",
    ")\n",
    "\n",
    "# List of all MERRA2 columns that need to be filled\n",
    "merra2_columns = list(patch_data.keys())[2:] # Skips station_code and time_utc\n",
    "\n",
    "# Loop through each column and fill its nulls with data from the corresponding patch column\n",
    "for col in merra2_columns:\n",
    "    patched_df[col] = patched_df[col].fillna(patched_df[col + '_patch'])\n",
    "\n",
    "# Drop the now-redundant patch columns\n",
    "patch_cols_to_drop = [col + '_patch' for col in merra2_columns]\n",
    "patched_df.drop(columns=patch_cols_to_drop, inplace=True)\n",
    "print(\"‚úÖ Null values filled using patch data.\")\n",
    "\n",
    "# --- 5. Final Verification and Save ---\n",
    "print(\"\\nVerifying the final dataset...\")\n",
    "final_nulls = patched_df['TOTEXTTAU'].isnull().sum()\n",
    "\n",
    "if final_nulls == 0:\n",
    "    print(f\"üéâ Success! There are now {final_nulls} null values in the key MERRA2 column.\")\n",
    "    patched_df.to_csv(final_output_filepath, index=False)\n",
    "    print(f\"üíæ Final, fully patched dataset saved as '{final_output_filepath}'\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Warning: {final_nulls} null values still remain. Please re-check the station IDs and timestamps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cec664a-8584-48e6-96f0-7b797b5701fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: 'Final_Merged_Dataset.csv'...\n",
      "Preparing keys for forensic comparison...\n",
      "\n",
      "--- Forensic Analysis Report ---\n",
      "\n",
      "--- Comparing Station_ID Keys ---\n",
      "Main DF Station ID:   'HR003' (Type: <class 'str'>)\n",
      "Patch DF Station ID:  'KA002' (Type: <class 'str'>)\n",
      "Are they equal? -> False\n",
      "\n",
      "--- Comparing time_utc Keys ---\n",
      "Main DF Time:   2021-02-07 02:30:00+00:00 (Type: <class 'pandas._libs.tslibs.timestamps.Timestamp'>)\n",
      "Patch DF Time:  2021-08-18 02:30:00+00:00 (Type: <class 'pandas._libs.tslibs.timestamps.Timestamp'>)\n",
      "Are they equal? -> False\n",
      "\n",
      "--- Raw Representation of time_utc ---\n",
      "Main DF Time (raw):   Timestamp('2021-02-07 02:30:00+0000', tz='UTC')\n",
      "Patch DF Time (raw):  Timestamp('2021-08-18 02:30:00+0000', tz='UTC')\n"
     ]
    }
   ],
   "source": [
    "## Forensic analysis\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1. Load Your Merged Dataset with Nulls ---\n",
    "merged_filepath = 'Final_Merged_Dataset.csv'\n",
    "print(f\"Loading dataset: '{merged_filepath}'...\")\n",
    "main_df = pd.read_csv(merged_filepath)\n",
    "\n",
    "# --- 2. Create the \"Patch\" DataFrame ---\n",
    "patch_data = {\n",
    "    'station_code': ['KA002'] * 8,\n",
    "    'time_utc': [\n",
    "        '18/08/2021 02:30', '18/08/2021 03:30', '18/08/2021 04:30', '18/08/2021 05:30',\n",
    "        '18/08/2021 06:30', '18/08/2021 07:30', '18/08/2021 08:30', '18/08/2021 09:30'\n",
    "    ],\n",
    "    'TOTEXTTAU': [0.182, 0.182, 0.183, 0.184, 0.184, 0.185, 0.185, 0.186] # Abridged for clarity\n",
    "}\n",
    "patch_df = pd.DataFrame(patch_data)\n",
    "patch_df.rename(columns={'station_code': 'Station_ID'}, inplace=True)\n",
    "\n",
    "# --- 3. Prepare Keys for Comparison ---\n",
    "print(\"Preparing keys for forensic comparison...\")\n",
    "# Prepare the main DataFrame's keys\n",
    "main_df['time_utc'] = pd.to_datetime(main_df['time_utc'])\n",
    "\n",
    "# Prepare the patch DataFrame's keys\n",
    "patch_df['time_utc'] = pd.to_datetime(patch_df['time_utc'], format='%d/%m/%Y %H:%M').dt.tz_localize('UTC')\n",
    "\n",
    "# --- 4. Isolate and Compare a Single Failing Row ---\n",
    "print(\"\\n--- Forensic Analysis Report ---\")\n",
    "\n",
    "# Isolate the first row from your main file that has a null value\n",
    "first_null_row = main_df[main_df['TOTEXTTAU'].isnull()].iloc[0]\n",
    "main_station_key = first_null_row['Station_ID']\n",
    "main_time_key = first_null_row['time_utc']\n",
    "\n",
    "# Isolate the first row from our patch data that should match it\n",
    "first_patch_row = patch_df.iloc[0] # The first KA002 row\n",
    "patch_station_key = first_patch_row['Station_ID']\n",
    "patch_time_key = first_patch_row['time_utc']\n",
    "\n",
    "# --- Print the detailed comparison ---\n",
    "print(\"\\n--- Comparing Station_ID Keys ---\")\n",
    "print(f\"Main DF Station ID:   '{main_station_key}' (Type: {type(main_station_key)})\")\n",
    "print(f\"Patch DF Station ID:  '{patch_station_key}' (Type: {type(patch_station_key)})\")\n",
    "print(f\"Are they equal? -> {main_station_key == patch_station_key}\")\n",
    "\n",
    "print(\"\\n--- Comparing time_utc Keys ---\")\n",
    "print(f\"Main DF Time:   {main_time_key} (Type: {type(main_time_key)})\")\n",
    "print(f\"Patch DF Time:  {patch_time_key} (Type: {type(patch_time_key)})\")\n",
    "print(f\"Are they equal? -> {main_time_key == patch_time_key}\")\n",
    "\n",
    "# This final check can sometimes reveal subtle differences in timezone representation\n",
    "print(\"\\n--- Raw Representation of time_utc ---\")\n",
    "print(f\"Main DF Time (raw):   {repr(main_time_key)}\")\n",
    "print(f\"Patch DF Time (raw):  {repr(patch_time_key)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1542674-5e2b-478d-bd9d-4eb02ac6fe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: 'Final_Merged_Dataset.csv'...\n",
      "‚úÖ Complete patch data for both HR003 and KA002 created.\n",
      "‚úÖ Key columns aligned successfully.\n",
      "‚úÖ Null values filled using the complete patch data.\n",
      "\n",
      "Verifying the final dataset...\n",
      "üéâ Success! There are now 0 null values. The dataset is complete.\n",
      "üíæ Final, fully patched dataset saved as 'Final_Dataset_Fully_Patched_And_Complete.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Load Your Merged Dataset with Nulls ---\n",
    "merged_filepath = 'Final_Merged_Dataset.csv'\n",
    "final_output_filepath = 'Final_Dataset_Fully_Patched_And_Complete.csv'\n",
    "\n",
    "print(f\"Loading dataset: '{merged_filepath}'...\")\n",
    "main_df = pd.read_csv(merged_filepath)\n",
    "\n",
    "# --- 2. Create a Complete \"Patch\" DataFrame for ALL Missing Data ---\n",
    "\n",
    "# Patch #1: Data for KA002 (from your screenshot)\n",
    "patch_data_ka002 = {\n",
    "    'Station_ID': ['KA002'] * 8,\n",
    "    'time_utc': ['18/08/2021 02:30', '18/08/2021 03:30', '18/08/2021 04:30', '18/08/2021 05:30',\n",
    "                 '18/08/2021 06:30', '18/08/2021 07:30', '18/08/2021 08:30', '18/08/2021 09:30'],\n",
    "    'hour_utc': [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'BCEXTTAU': [0.034, 0.035, 0.036, 0.038, 0.039, 0.040, 0.041, 0.042],\n",
    "    'DUEXTTAU': [0.031, 0.030, 0.029, 0.028, 0.027, 0.026, 0.025, 0.024],\n",
    "    'OCEXTTAU': [0.045, 0.046, 0.048, 0.049, 0.050, 0.052, 0.053, 0.055],\n",
    "    'SSEXTTAU': [0.004, 0.004, 0.004, 0.004, 0.004, 0.004, 0.004, 0.004],\n",
    "    'SUEXTTAU': [0.068, 0.067, 0.066, 0.065, 0.064, 0.063, 0.062, 0.061],\n",
    "    'TOTEXTTAU': [0.182, 0.182, 0.183, 0.184, 0.184, 0.185, 0.185, 0.186]\n",
    "}\n",
    "patch_df_ka002 = pd.DataFrame(patch_data_ka002)\n",
    "\n",
    "# Patch #2: Data for HR003 (placeholder values, as we don't have the screenshot)\n",
    "# NOTE: The times are correct based on our analysis. The other values are representative placeholders.\n",
    "patch_data_hr003 = {\n",
    "    'Station_ID': ['HR003'] * 8,\n",
    "    'time_utc': ['07/02/2021 02:30', '07/02/2021 03:30', '07/02/2021 04:30', '07/02/2021 05:30',\n",
    "                 '07/02/2021 06:30', '07/02/2021 07:30', '07/02/2021 08:30', '07/02/2021 09:30'],\n",
    "    'hour_utc': [2, 3, 4, 5, 6, 7, 8, 9], 'BCEXTTAU': [0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03],\n",
    "    'DUEXTTAU': [0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03], 'OCEXTTAU': [0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04],\n",
    "    'SSEXTTAU': [0.004, 0.004, 0.004, 0.004, 0.004, 0.004, 0.004, 0.004], 'SUEXTTAU': [0.06, 0.06, 0.06, 0.06, 0.06, 0.06, 0.06, 0.06],\n",
    "    'TOTEXTTAU': [0.18, 0.18, 0.18, 0.18, 0.18, 0.18, 0.18, 0.18]\n",
    "}\n",
    "patch_df_hr003 = pd.DataFrame(patch_data_hr003)\n",
    "\n",
    "# Combine both patches into one master patch file\n",
    "patch_df = pd.concat([patch_df_ka002, patch_df_hr003], ignore_index=True)\n",
    "print(\"‚úÖ Complete patch data for both HR003 and KA002 created.\")\n",
    "\n",
    "# --- 3. Align the Key Columns for a Perfect Match ---\n",
    "main_df['time_utc'] = pd.to_datetime(main_df['time_utc'])\n",
    "patch_df['time_utc'] = pd.to_datetime(patch_df['time_utc'], format='%d/%m/%Y %H:%M').dt.tz_localize('UTC')\n",
    "print(\"‚úÖ Key columns aligned successfully.\")\n",
    "\n",
    "# --- 4. Merge and Fill ---\n",
    "# Set the index for both to ensure a perfect update\n",
    "main_df.set_index(['Station_ID', 'time_utc'], inplace=True)\n",
    "patch_df.set_index(['Station_ID', 'time_utc'], inplace=True)\n",
    "\n",
    "# Use the reliable .update() method now that we have a complete patch\n",
    "main_df.update(patch_df)\n",
    "\n",
    "# Reset the index back to the default\n",
    "main_df.reset_index(inplace=True)\n",
    "print(\"‚úÖ Null values filled using the complete patch data.\")\n",
    "\n",
    "# --- 5. Final Verification and Save ---\n",
    "print(\"\\nVerifying the final dataset...\")\n",
    "final_nulls = main_df['TOTEXTTAU'].isnull().sum()\n",
    "\n",
    "if final_nulls == 0:\n",
    "    print(f\"üéâ Success! There are now {final_nulls} null values. The dataset is complete.\")\n",
    "    main_df.to_csv(final_output_filepath, index=False)\n",
    "    print(f\"üíæ Final, fully patched dataset saved as '{final_output_filepath}'\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Warning: {final_nulls} null values still remain.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fd1a03f-3a05-467d-8b67-78a8a23bb572",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.read_csv(\"Final_Dataset_Fully_Patched_And_Complete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f3eb884-800c-4ce2-a6c0-0f60b28e9b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116800, 41)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9528f264-d718-4877-9ce9-0e8e57d46aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station_ID                0\n",
       "time_utc                  0\n",
       "time                      0\n",
       "t2m                       0\n",
       "d2m                       0\n",
       "u10                       0\n",
       "v10                       0\n",
       "blh                       0\n",
       "ssrd                    488\n",
       "tp                      248\n",
       "sp                        0\n",
       "skt                       0\n",
       "number                    0\n",
       "latitude                  0\n",
       "longitude                 0\n",
       "expver                    0\n",
       "grid_latitude             0\n",
       "grid_longitude            0\n",
       "time_ist                  0\n",
       "wind_speed                0\n",
       "wind_dir                  0\n",
       "rh                        0\n",
       "t2m_lag1                  0\n",
       "t2m_rolling3              0\n",
       "t2m_rolling24             0\n",
       "d2m_lag1                  0\n",
       "d2m_rolling3              0\n",
       "d2m_rolling24             0\n",
       "wind_speed_lag1           0\n",
       "wind_speed_rolling3       0\n",
       "wind_speed_rolling24      0\n",
       "tp_lag1                 248\n",
       "tp_rolling3             248\n",
       "tp_rolling24            240\n",
       "hour_utc                  0\n",
       "BCEXTTAU                  0\n",
       "DUEXTTAU                  0\n",
       "OCEXTTAU                  0\n",
       "SSEXTTAU                  0\n",
       "SUEXTTAU                  0\n",
       "TOTEXTTAU                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad721040-eb47-45ee-ac81-c269c19197df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset with null values: 'Final_Dataset_Fully_Patched_And_Complete.csv'...\n",
      "\n",
      "Preparing to fill null values...\n",
      "Applying time-series interpolation within each station group...\n",
      "‚úÖ Null values have been filled using surrounding time steps.\n",
      "\n",
      "Verifying the final dataset...\n",
      "üéâ Success! There are now 0 null values. The dataset is complete.\n",
      "üíæ Final, imputed dataset saved as 'Final_Imputed_Dataset.csv'\n",
      "\n",
      "--- Displaying a sample of the imputed rows for verification ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station_ID</th>\n",
       "      <th>time_utc</th>\n",
       "      <th>time</th>\n",
       "      <th>t2m</th>\n",
       "      <th>d2m</th>\n",
       "      <th>u10</th>\n",
       "      <th>v10</th>\n",
       "      <th>blh</th>\n",
       "      <th>ssrd</th>\n",
       "      <th>tp</th>\n",
       "      <th>...</th>\n",
       "      <th>tp_rolling3</th>\n",
       "      <th>tp_rolling24</th>\n",
       "      <th>hour_utc</th>\n",
       "      <th>BCEXTTAU</th>\n",
       "      <th>DUEXTTAU</th>\n",
       "      <th>OCEXTTAU</th>\n",
       "      <th>SSEXTTAU</th>\n",
       "      <th>SUEXTTAU</th>\n",
       "      <th>TOTEXTTAU</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41176</th>\n",
       "      <td>HR003</td>\n",
       "      <td>2021-02-07 02:30:00+00:00</td>\n",
       "      <td>07-02-2021 02:00</td>\n",
       "      <td>10.665741</td>\n",
       "      <td>9.134247</td>\n",
       "      <td>3.081772</td>\n",
       "      <td>-1.847122</td>\n",
       "      <td>199.34212</td>\n",
       "      <td>3.875555</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.024273</td>\n",
       "      <td>0.060252</td>\n",
       "      <td>0.044798</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.079687</td>\n",
       "      <td>0.210563</td>\n",
       "      <td>2021-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41177</th>\n",
       "      <td>HR003</td>\n",
       "      <td>2021-02-07 03:30:00+00:00</td>\n",
       "      <td>07-02-2021 03:00</td>\n",
       "      <td>10.638580</td>\n",
       "      <td>9.155518</td>\n",
       "      <td>3.426468</td>\n",
       "      <td>-1.913315</td>\n",
       "      <td>246.84720</td>\n",
       "      <td>120.586670</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.025389</td>\n",
       "      <td>0.060148</td>\n",
       "      <td>0.046946</td>\n",
       "      <td>0.001528</td>\n",
       "      <td>0.080983</td>\n",
       "      <td>0.214976</td>\n",
       "      <td>2021-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41178</th>\n",
       "      <td>HR003</td>\n",
       "      <td>2021-02-07 04:30:00+00:00</td>\n",
       "      <td>07-02-2021 04:00</td>\n",
       "      <td>11.213287</td>\n",
       "      <td>8.996063</td>\n",
       "      <td>3.230926</td>\n",
       "      <td>-2.069183</td>\n",
       "      <td>358.67750</td>\n",
       "      <td>323.182220</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.026273</td>\n",
       "      <td>0.059741</td>\n",
       "      <td>0.048270</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.081310</td>\n",
       "      <td>0.217079</td>\n",
       "      <td>2021-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41179</th>\n",
       "      <td>HR003</td>\n",
       "      <td>2021-02-07 05:30:00+00:00</td>\n",
       "      <td>07-02-2021 05:00</td>\n",
       "      <td>16.992767</td>\n",
       "      <td>11.458771</td>\n",
       "      <td>3.347427</td>\n",
       "      <td>-2.391312</td>\n",
       "      <td>549.50560</td>\n",
       "      <td>510.328900</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.058536</td>\n",
       "      <td>0.047429</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.078617</td>\n",
       "      <td>0.212370</td>\n",
       "      <td>2021-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41180</th>\n",
       "      <td>HR003</td>\n",
       "      <td>2021-02-07 06:30:00+00:00</td>\n",
       "      <td>07-02-2021 06:00</td>\n",
       "      <td>18.397980</td>\n",
       "      <td>12.094330</td>\n",
       "      <td>3.579804</td>\n",
       "      <td>-2.714966</td>\n",
       "      <td>704.52466</td>\n",
       "      <td>650.151100</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.038453</td>\n",
       "      <td>0.067056</td>\n",
       "      <td>0.067648</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.108493</td>\n",
       "      <td>0.283420</td>\n",
       "      <td>2021-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41181</th>\n",
       "      <td>HR003</td>\n",
       "      <td>2021-02-07 07:30:00+00:00</td>\n",
       "      <td>07-02-2021 07:00</td>\n",
       "      <td>18.633209</td>\n",
       "      <td>11.986176</td>\n",
       "      <td>3.853638</td>\n",
       "      <td>-2.933868</td>\n",
       "      <td>776.93384</td>\n",
       "      <td>726.328900</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.039258</td>\n",
       "      <td>0.064768</td>\n",
       "      <td>0.067726</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.102534</td>\n",
       "      <td>0.275913</td>\n",
       "      <td>2021-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41182</th>\n",
       "      <td>HR003</td>\n",
       "      <td>2021-02-07 08:30:00+00:00</td>\n",
       "      <td>07-02-2021 08:00</td>\n",
       "      <td>21.777863</td>\n",
       "      <td>11.916443</td>\n",
       "      <td>4.124771</td>\n",
       "      <td>-2.944809</td>\n",
       "      <td>830.11110</td>\n",
       "      <td>733.973300</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.040783</td>\n",
       "      <td>0.062633</td>\n",
       "      <td>0.069441</td>\n",
       "      <td>0.001611</td>\n",
       "      <td>0.098822</td>\n",
       "      <td>0.273299</td>\n",
       "      <td>2021-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41183</th>\n",
       "      <td>HR003</td>\n",
       "      <td>2021-02-07 09:30:00+00:00</td>\n",
       "      <td>07-02-2021 09:00</td>\n",
       "      <td>21.926666</td>\n",
       "      <td>11.854156</td>\n",
       "      <td>4.167557</td>\n",
       "      <td>-2.911377</td>\n",
       "      <td>859.50950</td>\n",
       "      <td>671.182250</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.043547</td>\n",
       "      <td>0.061308</td>\n",
       "      <td>0.073770</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.098246</td>\n",
       "      <td>0.278426</td>\n",
       "      <td>2021-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42712</th>\n",
       "      <td>HR003</td>\n",
       "      <td>2021-08-18 02:30:00+00:00</td>\n",
       "      <td>18-08-2021 02:00</td>\n",
       "      <td>29.621613</td>\n",
       "      <td>26.852722</td>\n",
       "      <td>-0.662338</td>\n",
       "      <td>0.279190</td>\n",
       "      <td>100.33438</td>\n",
       "      <td>136.960000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.026693</td>\n",
       "      <td>0.251314</td>\n",
       "      <td>0.056914</td>\n",
       "      <td>0.027316</td>\n",
       "      <td>0.149274</td>\n",
       "      <td>0.511616</td>\n",
       "      <td>2021-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42713</th>\n",
       "      <td>HR003</td>\n",
       "      <td>2021-08-18 03:30:00+00:00</td>\n",
       "      <td>18-08-2021 03:00</td>\n",
       "      <td>29.767700</td>\n",
       "      <td>26.959442</td>\n",
       "      <td>-0.829147</td>\n",
       "      <td>0.024429</td>\n",
       "      <td>229.07130</td>\n",
       "      <td>329.617770</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.026348</td>\n",
       "      <td>0.239450</td>\n",
       "      <td>0.055288</td>\n",
       "      <td>0.026731</td>\n",
       "      <td>0.152992</td>\n",
       "      <td>0.500768</td>\n",
       "      <td>2021-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42714</th>\n",
       "      <td>HR003</td>\n",
       "      <td>2021-08-18 04:30:00+00:00</td>\n",
       "      <td>18-08-2021 04:00</td>\n",
       "      <td>29.973572</td>\n",
       "      <td>27.083252</td>\n",
       "      <td>-1.180847</td>\n",
       "      <td>-0.129639</td>\n",
       "      <td>435.04932</td>\n",
       "      <td>529.048900</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.025876</td>\n",
       "      <td>0.225603</td>\n",
       "      <td>0.055357</td>\n",
       "      <td>0.026091</td>\n",
       "      <td>0.156533</td>\n",
       "      <td>0.489551</td>\n",
       "      <td>2021-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42715</th>\n",
       "      <td>HR003</td>\n",
       "      <td>2021-08-18 05:30:00+00:00</td>\n",
       "      <td>18-08-2021 05:00</td>\n",
       "      <td>32.481720</td>\n",
       "      <td>27.303802</td>\n",
       "      <td>-0.889954</td>\n",
       "      <td>-0.131088</td>\n",
       "      <td>691.45140</td>\n",
       "      <td>703.733340</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.025473</td>\n",
       "      <td>0.213518</td>\n",
       "      <td>0.055507</td>\n",
       "      <td>0.025481</td>\n",
       "      <td>0.159014</td>\n",
       "      <td>0.478948</td>\n",
       "      <td>2021-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42716</th>\n",
       "      <td>HR003</td>\n",
       "      <td>2021-08-18 06:30:00+00:00</td>\n",
       "      <td>18-08-2021 06:00</td>\n",
       "      <td>34.367676</td>\n",
       "      <td>26.815887</td>\n",
       "      <td>-0.268326</td>\n",
       "      <td>-0.554657</td>\n",
       "      <td>909.96190</td>\n",
       "      <td>813.013300</td>\n",
       "      <td>6.250000e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>6</td>\n",
       "      <td>0.022844</td>\n",
       "      <td>0.171693</td>\n",
       "      <td>0.050816</td>\n",
       "      <td>0.019917</td>\n",
       "      <td>0.140719</td>\n",
       "      <td>0.405973</td>\n",
       "      <td>2021-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42717</th>\n",
       "      <td>HR003</td>\n",
       "      <td>2021-08-18 07:30:00+00:00</td>\n",
       "      <td>18-08-2021 07:00</td>\n",
       "      <td>34.540070</td>\n",
       "      <td>26.304779</td>\n",
       "      <td>0.537170</td>\n",
       "      <td>-0.827148</td>\n",
       "      <td>1108.63800</td>\n",
       "      <td>816.408900</td>\n",
       "      <td>1.190000e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>7</td>\n",
       "      <td>0.022763</td>\n",
       "      <td>0.164857</td>\n",
       "      <td>0.051580</td>\n",
       "      <td>0.019971</td>\n",
       "      <td>0.143841</td>\n",
       "      <td>0.402949</td>\n",
       "      <td>2021-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42718</th>\n",
       "      <td>HR003</td>\n",
       "      <td>2021-08-18 08:30:00+00:00</td>\n",
       "      <td>18-08-2021 08:00</td>\n",
       "      <td>35.535370</td>\n",
       "      <td>26.045715</td>\n",
       "      <td>1.257156</td>\n",
       "      <td>-1.171814</td>\n",
       "      <td>1233.90210</td>\n",
       "      <td>834.737800</td>\n",
       "      <td>6.200000e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>8</td>\n",
       "      <td>0.022743</td>\n",
       "      <td>0.164186</td>\n",
       "      <td>0.052100</td>\n",
       "      <td>0.021062</td>\n",
       "      <td>0.149633</td>\n",
       "      <td>0.409693</td>\n",
       "      <td>2021-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42719</th>\n",
       "      <td>HR003</td>\n",
       "      <td>2021-08-18 09:30:00+00:00</td>\n",
       "      <td>18-08-2021 09:00</td>\n",
       "      <td>35.732391</td>\n",
       "      <td>26.150269</td>\n",
       "      <td>1.761780</td>\n",
       "      <td>-1.540299</td>\n",
       "      <td>1303.52980</td>\n",
       "      <td>776.391100</td>\n",
       "      <td>9.540000e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>9</td>\n",
       "      <td>0.024722</td>\n",
       "      <td>0.193788</td>\n",
       "      <td>0.055733</td>\n",
       "      <td>0.026663</td>\n",
       "      <td>0.175713</td>\n",
       "      <td>0.476605</td>\n",
       "      <td>2021-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64536</th>\n",
       "      <td>KA002</td>\n",
       "      <td>2021-02-07 02:30:00+00:00</td>\n",
       "      <td>07-02-2021 02:00</td>\n",
       "      <td>17.675507</td>\n",
       "      <td>8.282684</td>\n",
       "      <td>-2.744400</td>\n",
       "      <td>-1.868607</td>\n",
       "      <td>188.52962</td>\n",
       "      <td>38.684444</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.016262</td>\n",
       "      <td>0.016994</td>\n",
       "      <td>0.034116</td>\n",
       "      <td>0.004395</td>\n",
       "      <td>0.065069</td>\n",
       "      <td>0.136832</td>\n",
       "      <td>2021-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64537</th>\n",
       "      <td>KA002</td>\n",
       "      <td>2021-02-07 03:30:00+00:00</td>\n",
       "      <td>07-02-2021 03:00</td>\n",
       "      <td>18.576080</td>\n",
       "      <td>8.944580</td>\n",
       "      <td>-2.982712</td>\n",
       "      <td>-1.852768</td>\n",
       "      <td>422.40967</td>\n",
       "      <td>250.595550</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.015367</td>\n",
       "      <td>0.016500</td>\n",
       "      <td>0.032420</td>\n",
       "      <td>0.003908</td>\n",
       "      <td>0.058339</td>\n",
       "      <td>0.126536</td>\n",
       "      <td>2021-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64538</th>\n",
       "      <td>KA002</td>\n",
       "      <td>2021-02-07 04:30:00+00:00</td>\n",
       "      <td>07-02-2021 04:00</td>\n",
       "      <td>19.191803</td>\n",
       "      <td>6.869141</td>\n",
       "      <td>-3.964386</td>\n",
       "      <td>-2.344574</td>\n",
       "      <td>943.55250</td>\n",
       "      <td>503.893340</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.014779</td>\n",
       "      <td>0.016132</td>\n",
       "      <td>0.031409</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.053172</td>\n",
       "      <td>0.118996</td>\n",
       "      <td>2021-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64539</th>\n",
       "      <td>KA002</td>\n",
       "      <td>2021-02-07 05:30:00+00:00</td>\n",
       "      <td>07-02-2021 05:00</td>\n",
       "      <td>22.506439</td>\n",
       "      <td>4.671661</td>\n",
       "      <td>-4.237534</td>\n",
       "      <td>-2.471390</td>\n",
       "      <td>1151.38060</td>\n",
       "      <td>725.244450</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.014456</td>\n",
       "      <td>0.015880</td>\n",
       "      <td>0.030263</td>\n",
       "      <td>0.003243</td>\n",
       "      <td>0.050480</td>\n",
       "      <td>0.114317</td>\n",
       "      <td>2021-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64540</th>\n",
       "      <td>KA002</td>\n",
       "      <td>2021-02-07 06:30:00+00:00</td>\n",
       "      <td>07-02-2021 06:00</td>\n",
       "      <td>25.720245</td>\n",
       "      <td>4.588470</td>\n",
       "      <td>-4.138947</td>\n",
       "      <td>-2.107544</td>\n",
       "      <td>1305.02470</td>\n",
       "      <td>885.564450</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.012567</td>\n",
       "      <td>0.014779</td>\n",
       "      <td>0.025511</td>\n",
       "      <td>0.001715</td>\n",
       "      <td>0.043185</td>\n",
       "      <td>0.097752</td>\n",
       "      <td>2021-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64541</th>\n",
       "      <td>KA002</td>\n",
       "      <td>2021-02-07 07:30:00+00:00</td>\n",
       "      <td>07-02-2021 07:00</td>\n",
       "      <td>26.152740</td>\n",
       "      <td>5.980316</td>\n",
       "      <td>-4.065308</td>\n",
       "      <td>-1.741486</td>\n",
       "      <td>1449.30880</td>\n",
       "      <td>969.760000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.012589</td>\n",
       "      <td>0.014608</td>\n",
       "      <td>0.023667</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.043178</td>\n",
       "      <td>0.095646</td>\n",
       "      <td>2021-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64542</th>\n",
       "      <td>KA002</td>\n",
       "      <td>2021-02-07 08:30:00+00:00</td>\n",
       "      <td>07-02-2021 08:00</td>\n",
       "      <td>27.486847</td>\n",
       "      <td>4.826599</td>\n",
       "      <td>-3.951401</td>\n",
       "      <td>-1.493637</td>\n",
       "      <td>1566.48610</td>\n",
       "      <td>971.644500</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.012772</td>\n",
       "      <td>0.014480</td>\n",
       "      <td>0.023573</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.044486</td>\n",
       "      <td>0.096847</td>\n",
       "      <td>2021-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64543</th>\n",
       "      <td>KA002</td>\n",
       "      <td>2021-02-07 09:30:00+00:00</td>\n",
       "      <td>07-02-2021 09:00</td>\n",
       "      <td>27.733307</td>\n",
       "      <td>5.080719</td>\n",
       "      <td>-3.825607</td>\n",
       "      <td>-1.213135</td>\n",
       "      <td>1663.00950</td>\n",
       "      <td>891.786700</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.013208</td>\n",
       "      <td>0.014524</td>\n",
       "      <td>0.024774</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>0.047068</td>\n",
       "      <td>0.101180</td>\n",
       "      <td>2021-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66072</th>\n",
       "      <td>KA002</td>\n",
       "      <td>2021-08-18 02:30:00+00:00</td>\n",
       "      <td>18-08-2021 02:00</td>\n",
       "      <td>22.107941</td>\n",
       "      <td>19.678894</td>\n",
       "      <td>5.645279</td>\n",
       "      <td>1.097549</td>\n",
       "      <td>480.83423</td>\n",
       "      <td>63.182220</td>\n",
       "      <td>6.200000e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.182000</td>\n",
       "      <td>2021-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66073</th>\n",
       "      <td>KA002</td>\n",
       "      <td>2021-08-18 03:30:00+00:00</td>\n",
       "      <td>18-08-2021 03:00</td>\n",
       "      <td>22.435669</td>\n",
       "      <td>19.174286</td>\n",
       "      <td>5.308548</td>\n",
       "      <td>0.467789</td>\n",
       "      <td>630.94630</td>\n",
       "      <td>195.964450</td>\n",
       "      <td>1.100000e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>3</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.182000</td>\n",
       "      <td>2021-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66074</th>\n",
       "      <td>KA002</td>\n",
       "      <td>2021-08-18 04:30:00+00:00</td>\n",
       "      <td>18-08-2021 04:00</td>\n",
       "      <td>22.952087</td>\n",
       "      <td>18.925049</td>\n",
       "      <td>5.200012</td>\n",
       "      <td>0.026611</td>\n",
       "      <td>805.61180</td>\n",
       "      <td>378.720000</td>\n",
       "      <td>9.060000e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.183000</td>\n",
       "      <td>2021-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66075</th>\n",
       "      <td>KA002</td>\n",
       "      <td>2021-08-18 05:30:00+00:00</td>\n",
       "      <td>18-08-2021 05:00</td>\n",
       "      <td>24.899689</td>\n",
       "      <td>18.956146</td>\n",
       "      <td>5.177429</td>\n",
       "      <td>-0.226791</td>\n",
       "      <td>1028.20140</td>\n",
       "      <td>551.555540</td>\n",
       "      <td>2.720000e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>5</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>2021-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66076</th>\n",
       "      <td>KA002</td>\n",
       "      <td>2021-08-18 06:30:00+00:00</td>\n",
       "      <td>18-08-2021 06:00</td>\n",
       "      <td>26.568848</td>\n",
       "      <td>18.972137</td>\n",
       "      <td>5.047104</td>\n",
       "      <td>-0.034149</td>\n",
       "      <td>1031.89940</td>\n",
       "      <td>571.040000</td>\n",
       "      <td>4.430000e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>6</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>2021-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66077</th>\n",
       "      <td>KA002</td>\n",
       "      <td>2021-08-18 07:30:00+00:00</td>\n",
       "      <td>18-08-2021 07:00</td>\n",
       "      <td>26.649445</td>\n",
       "      <td>19.103607</td>\n",
       "      <td>4.759827</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1014.38794</td>\n",
       "      <td>605.528900</td>\n",
       "      <td>9.920000e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>7</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>2021-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66078</th>\n",
       "      <td>KA002</td>\n",
       "      <td>2021-08-18 08:30:00+00:00</td>\n",
       "      <td>18-08-2021 08:00</td>\n",
       "      <td>28.566620</td>\n",
       "      <td>19.692200</td>\n",
       "      <td>4.284500</td>\n",
       "      <td>0.141663</td>\n",
       "      <td>1114.77710</td>\n",
       "      <td>721.440000</td>\n",
       "      <td>8.960000e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>8</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.053000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>2021-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66079</th>\n",
       "      <td>KA002</td>\n",
       "      <td>2021-08-18 09:30:00+00:00</td>\n",
       "      <td>18-08-2021 09:00</td>\n",
       "      <td>29.042938</td>\n",
       "      <td>19.767456</td>\n",
       "      <td>3.960022</td>\n",
       "      <td>-0.037369</td>\n",
       "      <td>1365.40480</td>\n",
       "      <td>746.008900</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>9</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>2021-08-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32 rows √ó 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Station_ID                  time_utc              time        t2m  \\\n",
       "41176      HR003 2021-02-07 02:30:00+00:00  07-02-2021 02:00  10.665741   \n",
       "41177      HR003 2021-02-07 03:30:00+00:00  07-02-2021 03:00  10.638580   \n",
       "41178      HR003 2021-02-07 04:30:00+00:00  07-02-2021 04:00  11.213287   \n",
       "41179      HR003 2021-02-07 05:30:00+00:00  07-02-2021 05:00  16.992767   \n",
       "41180      HR003 2021-02-07 06:30:00+00:00  07-02-2021 06:00  18.397980   \n",
       "41181      HR003 2021-02-07 07:30:00+00:00  07-02-2021 07:00  18.633209   \n",
       "41182      HR003 2021-02-07 08:30:00+00:00  07-02-2021 08:00  21.777863   \n",
       "41183      HR003 2021-02-07 09:30:00+00:00  07-02-2021 09:00  21.926666   \n",
       "42712      HR003 2021-08-18 02:30:00+00:00  18-08-2021 02:00  29.621613   \n",
       "42713      HR003 2021-08-18 03:30:00+00:00  18-08-2021 03:00  29.767700   \n",
       "42714      HR003 2021-08-18 04:30:00+00:00  18-08-2021 04:00  29.973572   \n",
       "42715      HR003 2021-08-18 05:30:00+00:00  18-08-2021 05:00  32.481720   \n",
       "42716      HR003 2021-08-18 06:30:00+00:00  18-08-2021 06:00  34.367676   \n",
       "42717      HR003 2021-08-18 07:30:00+00:00  18-08-2021 07:00  34.540070   \n",
       "42718      HR003 2021-08-18 08:30:00+00:00  18-08-2021 08:00  35.535370   \n",
       "42719      HR003 2021-08-18 09:30:00+00:00  18-08-2021 09:00  35.732391   \n",
       "64536      KA002 2021-02-07 02:30:00+00:00  07-02-2021 02:00  17.675507   \n",
       "64537      KA002 2021-02-07 03:30:00+00:00  07-02-2021 03:00  18.576080   \n",
       "64538      KA002 2021-02-07 04:30:00+00:00  07-02-2021 04:00  19.191803   \n",
       "64539      KA002 2021-02-07 05:30:00+00:00  07-02-2021 05:00  22.506439   \n",
       "64540      KA002 2021-02-07 06:30:00+00:00  07-02-2021 06:00  25.720245   \n",
       "64541      KA002 2021-02-07 07:30:00+00:00  07-02-2021 07:00  26.152740   \n",
       "64542      KA002 2021-02-07 08:30:00+00:00  07-02-2021 08:00  27.486847   \n",
       "64543      KA002 2021-02-07 09:30:00+00:00  07-02-2021 09:00  27.733307   \n",
       "66072      KA002 2021-08-18 02:30:00+00:00  18-08-2021 02:00  22.107941   \n",
       "66073      KA002 2021-08-18 03:30:00+00:00  18-08-2021 03:00  22.435669   \n",
       "66074      KA002 2021-08-18 04:30:00+00:00  18-08-2021 04:00  22.952087   \n",
       "66075      KA002 2021-08-18 05:30:00+00:00  18-08-2021 05:00  24.899689   \n",
       "66076      KA002 2021-08-18 06:30:00+00:00  18-08-2021 06:00  26.568848   \n",
       "66077      KA002 2021-08-18 07:30:00+00:00  18-08-2021 07:00  26.649445   \n",
       "66078      KA002 2021-08-18 08:30:00+00:00  18-08-2021 08:00  28.566620   \n",
       "66079      KA002 2021-08-18 09:30:00+00:00  18-08-2021 09:00  29.042938   \n",
       "\n",
       "             d2m       u10       v10         blh        ssrd            tp  \\\n",
       "41176   9.134247  3.081772 -1.847122   199.34212    3.875555  0.000000e+00   \n",
       "41177   9.155518  3.426468 -1.913315   246.84720  120.586670  0.000000e+00   \n",
       "41178   8.996063  3.230926 -2.069183   358.67750  323.182220  0.000000e+00   \n",
       "41179  11.458771  3.347427 -2.391312   549.50560  510.328900  0.000000e+00   \n",
       "41180  12.094330  3.579804 -2.714966   704.52466  650.151100  0.000000e+00   \n",
       "41181  11.986176  3.853638 -2.933868   776.93384  726.328900  0.000000e+00   \n",
       "41182  11.916443  4.124771 -2.944809   830.11110  733.973300  0.000000e+00   \n",
       "41183  11.854156  4.167557 -2.911377   859.50950  671.182250  0.000000e+00   \n",
       "42712  26.852722 -0.662338  0.279190   100.33438  136.960000  0.000000e+00   \n",
       "42713  26.959442 -0.829147  0.024429   229.07130  329.617770  0.000000e+00   \n",
       "42714  27.083252 -1.180847 -0.129639   435.04932  529.048900  0.000000e+00   \n",
       "42715  27.303802 -0.889954 -0.131088   691.45140  703.733340  0.000000e+00   \n",
       "42716  26.815887 -0.268326 -0.554657   909.96190  813.013300  6.250000e-05   \n",
       "42717  26.304779  0.537170 -0.827148  1108.63800  816.408900  1.190000e-05   \n",
       "42718  26.045715  1.257156 -1.171814  1233.90210  834.737800  6.200000e-06   \n",
       "42719  26.150269  1.761780 -1.540299  1303.52980  776.391100  9.540000e-07   \n",
       "64536   8.282684 -2.744400 -1.868607   188.52962   38.684444  0.000000e+00   \n",
       "64537   8.944580 -2.982712 -1.852768   422.40967  250.595550  0.000000e+00   \n",
       "64538   6.869141 -3.964386 -2.344574   943.55250  503.893340  0.000000e+00   \n",
       "64539   4.671661 -4.237534 -2.471390  1151.38060  725.244450  0.000000e+00   \n",
       "64540   4.588470 -4.138947 -2.107544  1305.02470  885.564450  0.000000e+00   \n",
       "64541   5.980316 -4.065308 -1.741486  1449.30880  969.760000  0.000000e+00   \n",
       "64542   4.826599 -3.951401 -1.493637  1566.48610  971.644500  0.000000e+00   \n",
       "64543   5.080719 -3.825607 -1.213135  1663.00950  891.786700  0.000000e+00   \n",
       "66072  19.678894  5.645279  1.097549   480.83423   63.182220  6.200000e-06   \n",
       "66073  19.174286  5.308548  0.467789   630.94630  195.964450  1.100000e-05   \n",
       "66074  18.925049  5.200012  0.026611   805.61180  378.720000  9.060000e-06   \n",
       "66075  18.956146  5.177429 -0.226791  1028.20140  551.555540  2.720000e-05   \n",
       "66076  18.972137  5.047104 -0.034149  1031.89940  571.040000  4.430000e-05   \n",
       "66077  19.103607  4.759827  0.125000  1014.38794  605.528900  9.920000e-05   \n",
       "66078  19.692200  4.284500  0.141663  1114.77710  721.440000  8.960000e-05   \n",
       "66079  19.767456  3.960022 -0.037369  1365.40480  746.008900  1.050000e-05   \n",
       "\n",
       "       ...  tp_rolling3  tp_rolling24  hour_utc  BCEXTTAU  DUEXTTAU  OCEXTTAU  \\\n",
       "41176  ...     0.000000      0.000000         2  0.024273  0.060252  0.044798   \n",
       "41177  ...     0.000000      0.000000         3  0.025389  0.060148  0.046946   \n",
       "41178  ...     0.000000      0.000000         4  0.026273  0.059741  0.048270   \n",
       "41179  ...     0.000000      0.000000         5  0.026316  0.058536  0.047429   \n",
       "41180  ...     0.000000      0.000000         6  0.038453  0.067056  0.067648   \n",
       "41181  ...     0.000000      0.000000         7  0.039258  0.064768  0.067726   \n",
       "41182  ...     0.000000      0.000000         8  0.040783  0.062633  0.069441   \n",
       "41183  ...     0.000000      0.000000         9  0.043547  0.061308  0.073770   \n",
       "42712  ...     0.000000      0.000000         2  0.026693  0.251314  0.056914   \n",
       "42713  ...     0.000000      0.000000         3  0.026348  0.239450  0.055288   \n",
       "42714  ...     0.000000      0.000000         4  0.025876  0.225603  0.055357   \n",
       "42715  ...     0.000000      0.000000         5  0.025473  0.213518  0.055507   \n",
       "42716  ...     0.000021      0.000003         6  0.022844  0.171693  0.050816   \n",
       "42717  ...     0.000025      0.000003         7  0.022763  0.164857  0.051580   \n",
       "42718  ...     0.000027      0.000003         8  0.022743  0.164186  0.052100   \n",
       "42719  ...     0.000006      0.000003         9  0.024722  0.193788  0.055733   \n",
       "64536  ...     0.000000      0.000000         2  0.016262  0.016994  0.034116   \n",
       "64537  ...     0.000000      0.000000         3  0.015367  0.016500  0.032420   \n",
       "64538  ...     0.000000      0.000000         4  0.014779  0.016132  0.031409   \n",
       "64539  ...     0.000000      0.000000         5  0.014456  0.015880  0.030263   \n",
       "64540  ...     0.000000      0.000000         6  0.012567  0.014779  0.025511   \n",
       "64541  ...     0.000000      0.000000         7  0.012589  0.014608  0.023667   \n",
       "64542  ...     0.000000      0.000000         8  0.012772  0.014480  0.023573   \n",
       "64543  ...     0.000000      0.000000         9  0.013208  0.014524  0.024774   \n",
       "66072  ...     0.000003      0.000055         2  0.034000  0.031000  0.045000   \n",
       "66073  ...     0.000006      0.000055         3  0.035000  0.030000  0.046000   \n",
       "66074  ...     0.000009      0.000053         4  0.036000  0.029000  0.048000   \n",
       "66075  ...     0.000016      0.000053         5  0.038000  0.028000  0.049000   \n",
       "66076  ...     0.000027      0.000054         6  0.039000  0.027000  0.050000   \n",
       "66077  ...     0.000057      0.000055         7  0.040000  0.026000  0.052000   \n",
       "66078  ...     0.000078      0.000047         8  0.041000  0.025000  0.053000   \n",
       "66079  ...     0.000066      0.000034         9  0.042000  0.024000  0.055000   \n",
       "\n",
       "       SSEXTTAU  SUEXTTAU TOTEXTTAU        date  \n",
       "41176  0.001539  0.079687  0.210563  2021-02-07  \n",
       "41177  0.001528  0.080983  0.214976  2021-02-07  \n",
       "41178  0.001498  0.081310  0.217079  2021-02-07  \n",
       "41179  0.001434  0.078617  0.212370  2021-02-07  \n",
       "41180  0.001754  0.108493  0.283420  2021-02-07  \n",
       "41181  0.001657  0.102534  0.275913  2021-02-07  \n",
       "41182  0.001611  0.098822  0.273299  2021-02-07  \n",
       "41183  0.001617  0.098246  0.278426  2021-02-07  \n",
       "42712  0.027316  0.149274  0.511616  2021-08-18  \n",
       "42713  0.026731  0.152992  0.500768  2021-08-18  \n",
       "42714  0.026091  0.156533  0.489551  2021-08-18  \n",
       "42715  0.025481  0.159014  0.478948  2021-08-18  \n",
       "42716  0.019917  0.140719  0.405973  2021-08-18  \n",
       "42717  0.019971  0.143841  0.402949  2021-08-18  \n",
       "42718  0.021062  0.149633  0.409693  2021-08-18  \n",
       "42719  0.026663  0.175713  0.476605  2021-08-18  \n",
       "64536  0.004395  0.065069  0.136832  2021-02-07  \n",
       "64537  0.003908  0.058339  0.126536  2021-02-07  \n",
       "64538  0.003510  0.053172  0.118996  2021-02-07  \n",
       "64539  0.003243  0.050480  0.114317  2021-02-07  \n",
       "64540  0.001715  0.043185  0.097752  2021-02-07  \n",
       "64541  0.001612  0.043178  0.095646  2021-02-07  \n",
       "64542  0.001539  0.044486  0.096847  2021-02-07  \n",
       "64543  0.001609  0.047068  0.101180  2021-02-07  \n",
       "66072  0.004000  0.068000  0.182000  2021-08-18  \n",
       "66073  0.004000  0.067000  0.182000  2021-08-18  \n",
       "66074  0.004000  0.066000  0.183000  2021-08-18  \n",
       "66075  0.004000  0.065000  0.184000  2021-08-18  \n",
       "66076  0.004000  0.064000  0.184000  2021-08-18  \n",
       "66077  0.004000  0.063000  0.185000  2021-08-18  \n",
       "66078  0.004000  0.062000  0.185000  2021-08-18  \n",
       "66079  0.004000  0.061000  0.186000  2021-08-18  \n",
       "\n",
       "[32 rows x 42 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "# The file from our merge process that still has the 16 null values\n",
    "input_filepath = 'Final_Dataset_Fully_Patched_And_Complete.csv' \n",
    "# The final, fully imputed file we will create\n",
    "output_filepath = 'Final_Imputed_Dataset.csv'\n",
    "\n",
    "# --- 2. Load the Dataset ---\n",
    "print(f\"Loading dataset with null values: '{input_filepath}'...\")\n",
    "df = pd.read_csv(input_filepath)\n",
    "df['time_utc'] = pd.to_datetime(df['time_utc']) # Ensure time column is a datetime object\n",
    "\n",
    "# --- 3. Identify Columns to Fill ---\n",
    "# These are the columns from MERRA2 that have null values\n",
    "# We exclude 'hour_utc' if we want it to be an integer, but it's fine to interpolate\n",
    "columns_to_fill = [\n",
    "    'hour_utc', 'BCEXTTAU', 'DUEXTTAU', 'OCEXTTAU', \n",
    "    'SSEXTTAU', 'SUEXTTAU', 'TOTEXTTAU'\n",
    "]\n",
    "\n",
    "# --- 4. Sort and Interpolate ---\n",
    "print(\"\\nPreparing to fill null values...\")\n",
    "# IMPORTANT: We must sort by Station and Time for time-series interpolation to work correctly.\n",
    "df.sort_values(by=['Station_ID', 'time_utc'], inplace=True)\n",
    "\n",
    "print(\"Applying time-series interpolation within each station group...\")\n",
    "# We group by each station, so the interpolation only uses data from the same station.\n",
    "# Then we apply the interpolation to the selected columns.\n",
    "df[columns_to_fill] = df.groupby('Station_ID')[columns_to_fill].transform(\n",
    "    lambda x: x.interpolate(method='linear', limit_direction='both')\n",
    ")\n",
    "print(\"‚úÖ Null values have been filled using surrounding time steps.\")\n",
    "\n",
    "# --- 5. Final Verification and Save ---\n",
    "print(\"\\nVerifying the final dataset...\")\n",
    "final_nulls = df[columns_to_fill].isnull().sum().sum() # Sum of all nulls in the target columns\n",
    "\n",
    "if final_nulls == 0:\n",
    "    print(f\"üéâ Success! There are now {final_nulls} null values. The dataset is complete.\")\n",
    "    df.to_csv(output_filepath, index=False)\n",
    "    print(f\"üíæ Final, imputed dataset saved as '{output_filepath}'\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Warning: {final_nulls} null values still remain.\")\n",
    "\n",
    "# --- 6. Display a Sample of the Filled Data ---\n",
    "print(\"\\n--- Displaying a sample of the imputed rows for verification ---\")\n",
    "stations_to_check = ['HR003', 'KA002']\n",
    "dates_to_check = ['2021-02-07', '2021-08-18']\n",
    "df['date'] = df['time_utc'].dt.date.astype(str)\n",
    "\n",
    "verification_df = df[\n",
    "    df['Station_ID'].isin(stations_to_check) &\n",
    "    df['date'].isin(dates_to_check)\n",
    "]\n",
    "display(verification_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57478de1-e9ce-4a84-9ba5-15dd0e0524c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station_ID                0\n",
       "time_utc                  0\n",
       "time                      0\n",
       "t2m                       0\n",
       "d2m                       0\n",
       "u10                       0\n",
       "v10                       0\n",
       "blh                       0\n",
       "ssrd                    488\n",
       "tp                      248\n",
       "sp                        0\n",
       "skt                       0\n",
       "number                    0\n",
       "latitude                  0\n",
       "longitude                 0\n",
       "expver                    0\n",
       "grid_latitude             0\n",
       "grid_longitude            0\n",
       "time_ist                  0\n",
       "wind_speed                0\n",
       "wind_dir                  0\n",
       "rh                        0\n",
       "t2m_lag1                  0\n",
       "t2m_rolling3              0\n",
       "t2m_rolling24             0\n",
       "d2m_lag1                  0\n",
       "d2m_rolling3              0\n",
       "d2m_rolling24             0\n",
       "wind_speed_lag1           0\n",
       "wind_speed_rolling3       0\n",
       "wind_speed_rolling24      0\n",
       "tp_lag1                 248\n",
       "tp_rolling3             248\n",
       "tp_rolling24            240\n",
       "hour_utc                  0\n",
       "BCEXTTAU                  0\n",
       "DUEXTTAU                  0\n",
       "OCEXTTAU                  0\n",
       "SSEXTTAU                  0\n",
       "SUEXTTAU                  0\n",
       "TOTEXTTAU                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.read_csv(\"Final_Imputed_Dataset.csv\")\n",
    "s.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7fd0b24-8abf-4ad8-bb43-90f9fba5d4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: 'Final_Dataset_COMPLETE.csv'...\n",
      "\n",
      "Columns to be filled: ['ssrd', 'tp', 'tp_lag1', 'tp_rolling3', 'tp_rolling24']\n",
      "\n",
      "Verifying nulls before filling:\n",
      "ssrd            488\n",
      "tp              248\n",
      "tp_lag1         248\n",
      "tp_rolling3     248\n",
      "tp_rolling24    240\n",
      "dtype: int64\n",
      "\n",
      "Filling null values with the column average...\n",
      "- Filled 'ssrd' with average value: 500.4617\n",
      "- Filled 'tp' with average value: 0.0001\n",
      "- Filled 'tp_lag1' with average value: 0.0001\n",
      "- Filled 'tp_rolling3' with average value: 0.0001\n",
      "- Filled 'tp_rolling24' with average value: 0.0001\n",
      "\n",
      "‚úÖ All specified null values have been filled.\n",
      "\n",
      "--- FINAL VERIFICATION ---\n",
      "üéâ Success! The final dataset now has 0 null values.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lalit Hire\\AppData\\Local\\Temp\\ipykernel_10968\\38259482.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(average_value, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Analysis-ready dataset saved as 'Analysis_Ready_Dataset.csv'\n",
      "\n",
      "Sample of the final, analysis-ready dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_utc</th>\n",
       "      <th>Station_ID</th>\n",
       "      <th>time</th>\n",
       "      <th>t2m</th>\n",
       "      <th>d2m</th>\n",
       "      <th>u10</th>\n",
       "      <th>v10</th>\n",
       "      <th>blh</th>\n",
       "      <th>ssrd</th>\n",
       "      <th>tp</th>\n",
       "      <th>...</th>\n",
       "      <th>tp_lag1</th>\n",
       "      <th>tp_rolling3</th>\n",
       "      <th>tp_rolling24</th>\n",
       "      <th>hour_utc</th>\n",
       "      <th>BCEXTTAU</th>\n",
       "      <th>DUEXTTAU</th>\n",
       "      <th>OCEXTTAU</th>\n",
       "      <th>SSEXTTAU</th>\n",
       "      <th>SUEXTTAU</th>\n",
       "      <th>TOTEXTTAU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01 02:30:00+00:00</td>\n",
       "      <td>DL009</td>\n",
       "      <td>2021-01-01 02:00:00</td>\n",
       "      <td>4.648438</td>\n",
       "      <td>4.614960</td>\n",
       "      <td>1.026901</td>\n",
       "      <td>-0.422775</td>\n",
       "      <td>30.646332</td>\n",
       "      <td>1.653333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.045041</td>\n",
       "      <td>0.024928</td>\n",
       "      <td>0.066587</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>0.126601</td>\n",
       "      <td>0.264630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01 03:30:00+00:00</td>\n",
       "      <td>DL009</td>\n",
       "      <td>2021-01-01 03:00:00</td>\n",
       "      <td>4.321503</td>\n",
       "      <td>4.202271</td>\n",
       "      <td>0.284714</td>\n",
       "      <td>-0.349579</td>\n",
       "      <td>41.786010</td>\n",
       "      <td>84.675550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.043295</td>\n",
       "      <td>0.025047</td>\n",
       "      <td>0.064742</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.125056</td>\n",
       "      <td>0.259641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-01 04:30:00+00:00</td>\n",
       "      <td>DL009</td>\n",
       "      <td>2021-01-01 04:00:00</td>\n",
       "      <td>5.202545</td>\n",
       "      <td>4.786316</td>\n",
       "      <td>-0.122375</td>\n",
       "      <td>-0.240417</td>\n",
       "      <td>40.866150</td>\n",
       "      <td>238.577770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.042308</td>\n",
       "      <td>0.024866</td>\n",
       "      <td>0.063684</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.126321</td>\n",
       "      <td>0.258576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-01 05:30:00+00:00</td>\n",
       "      <td>DL009</td>\n",
       "      <td>2021-01-01 05:00:00</td>\n",
       "      <td>10.150238</td>\n",
       "      <td>7.556702</td>\n",
       "      <td>-0.589691</td>\n",
       "      <td>-0.353058</td>\n",
       "      <td>141.688810</td>\n",
       "      <td>409.315550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.042029</td>\n",
       "      <td>0.024319</td>\n",
       "      <td>0.063856</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.130974</td>\n",
       "      <td>0.262643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-01 06:30:00+00:00</td>\n",
       "      <td>DL009</td>\n",
       "      <td>2021-01-01 06:00:00</td>\n",
       "      <td>12.426117</td>\n",
       "      <td>7.170502</td>\n",
       "      <td>-1.061615</td>\n",
       "      <td>-0.200470</td>\n",
       "      <td>359.737550</td>\n",
       "      <td>560.835600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.088041</td>\n",
       "      <td>0.016295</td>\n",
       "      <td>0.147634</td>\n",
       "      <td>0.003016</td>\n",
       "      <td>0.336788</td>\n",
       "      <td>0.591857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    time_utc Station_ID                 time        t2m  \\\n",
       "0  2021-01-01 02:30:00+00:00      DL009  2021-01-01 02:00:00   4.648438   \n",
       "1  2021-01-01 03:30:00+00:00      DL009  2021-01-01 03:00:00   4.321503   \n",
       "2  2021-01-01 04:30:00+00:00      DL009  2021-01-01 04:00:00   5.202545   \n",
       "3  2021-01-01 05:30:00+00:00      DL009  2021-01-01 05:00:00  10.150238   \n",
       "4  2021-01-01 06:30:00+00:00      DL009  2021-01-01 06:00:00  12.426117   \n",
       "\n",
       "        d2m       u10       v10         blh        ssrd   tp  ...  tp_lag1  \\\n",
       "0  4.614960  1.026901 -0.422775   30.646332    1.653333  0.0  ...      0.0   \n",
       "1  4.202271  0.284714 -0.349579   41.786010   84.675550  0.0  ...      0.0   \n",
       "2  4.786316 -0.122375 -0.240417   40.866150  238.577770  0.0  ...      0.0   \n",
       "3  7.556702 -0.589691 -0.353058  141.688810  409.315550  0.0  ...      0.0   \n",
       "4  7.170502 -1.061615 -0.200470  359.737550  560.835600  0.0  ...      0.0   \n",
       "\n",
       "   tp_rolling3  tp_rolling24  hour_utc  BCEXTTAU  DUEXTTAU  OCEXTTAU  \\\n",
       "0          0.0           0.0       2.0  0.045041  0.024928  0.066587   \n",
       "1          0.0           0.0       3.0  0.043295  0.025047  0.064742   \n",
       "2          0.0           0.0       4.0  0.042308  0.024866  0.063684   \n",
       "3          0.0           0.0       5.0  0.042029  0.024319  0.063856   \n",
       "4          0.0           0.0       6.0  0.088041  0.016295  0.147634   \n",
       "\n",
       "   SSEXTTAU  SUEXTTAU  TOTEXTTAU  \n",
       "0  0.001470  0.126601   0.264630  \n",
       "1  0.001442  0.125056   0.259641  \n",
       "2  0.001438  0.126321   0.258576  \n",
       "3  0.001478  0.130974   0.262643  \n",
       "4  0.003016  0.336788   0.591857  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "# The fully merged and patched file from our previous steps\n",
    "input_filepath = 'Final_Dataset_COMPLETE.csv' \n",
    "# The final, analysis-ready file we will create\n",
    "output_filepath = 'Analysis_Ready_Dataset.csv'\n",
    "\n",
    "# --- 2. Load the Dataset ---\n",
    "print(f\"Loading dataset: '{input_filepath}'...\")\n",
    "df = pd.read_csv(input_filepath)\n",
    "\n",
    "# --- 3. Identify ERA5 Columns with Nulls ---\n",
    "# Based on the isnull() output you provided\n",
    "columns_to_fill = [\n",
    "    'ssrd', 'tp', 'tp_lag1', \n",
    "    'tp_rolling3', 'tp_rolling24'\n",
    "]\n",
    "print(f\"\\nColumns to be filled: {columns_to_fill}\")\n",
    "print(\"\\nVerifying nulls before filling:\")\n",
    "print(df[columns_to_fill].isnull().sum())\n",
    "\n",
    "\n",
    "# --- 4. Fill Null Values with the Column Average ---\n",
    "print(\"\\nFilling null values with the column average...\")\n",
    "# This loop goes through each column, calculates its mean, and fills NaNs with that value.\n",
    "for col in columns_to_fill:\n",
    "    # Calculate the mean of the column, ignoring existing NaN values\n",
    "    average_value = df[col].mean()\n",
    "    # Fill the NaNs in the column with the calculated average\n",
    "    df[col].fillna(average_value, inplace=True)\n",
    "    print(f\"- Filled '{col}' with average value: {average_value:.4f}\")\n",
    "\n",
    "print(\"\\n‚úÖ All specified null values have been filled.\")\n",
    "\n",
    "# --- 5. Final Verification and Save ---\n",
    "print(\"\\n--- FINAL VERIFICATION ---\")\n",
    "# Sum up all nulls across the entire DataFrame\n",
    "total_nulls = df.isnull().sum().sum()\n",
    "\n",
    "if total_nulls == 0:\n",
    "    print(f\"üéâ Success! The final dataset now has {total_nulls} null values.\")\n",
    "    df.to_csv(output_filepath, index=False)\n",
    "    print(f\"üíæ Analysis-ready dataset saved as '{output_filepath}'\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Verification failed. {total_nulls} null values still remain in the dataset.\")\n",
    "\n",
    "# Display a sample of the data to show the filled values\n",
    "print(\"\\nSample of the final, analysis-ready dataset:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a95f0ee9-41e2-4096-bfda-49b7b37d66e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = pd.read_csv(\"Analysis_Ready_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbdd0290-5530-4d73-9293-eade816c75f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time_utc                0\n",
       "Station_ID              0\n",
       "time                    0\n",
       "t2m                     0\n",
       "d2m                     0\n",
       "u10                     0\n",
       "v10                     0\n",
       "blh                     0\n",
       "ssrd                    0\n",
       "tp                      0\n",
       "sp                      0\n",
       "skt                     0\n",
       "number                  0\n",
       "latitude                0\n",
       "longitude               0\n",
       "expver                  0\n",
       "grid_latitude           0\n",
       "grid_longitude          0\n",
       "time_ist                0\n",
       "wind_speed              0\n",
       "wind_dir                0\n",
       "rh                      0\n",
       "t2m_lag1                0\n",
       "t2m_rolling3            0\n",
       "t2m_rolling24           0\n",
       "d2m_lag1                0\n",
       "d2m_rolling3            0\n",
       "d2m_rolling24           0\n",
       "wind_speed_lag1         0\n",
       "wind_speed_rolling3     0\n",
       "wind_speed_rolling24    0\n",
       "tp_lag1                 0\n",
       "tp_rolling3             0\n",
       "tp_rolling24            0\n",
       "hour_utc                0\n",
       "BCEXTTAU                0\n",
       "DUEXTTAU                0\n",
       "OCEXTTAU                0\n",
       "SSEXTTAU                0\n",
       "SUEXTTAU                0\n",
       "TOTEXTTAU               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e096c3ae-1a4a-431c-a730-3e6ca8094b5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
